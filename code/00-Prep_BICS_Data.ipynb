{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0c3bdef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "27b4ccc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/chrissoria/Documents/Research/BICS_Political_Polarization'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "da750851",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/chrissoria/Documents/Research/BICS_Political_Polarization/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f5a7d4",
   "metadata": {},
   "source": [
    "some ZIP Codes, such as \"unique\" ZIPs that are often tied to an internal mail-routing mechanism (such as UC Berkeley which has its own internal ZIP code and mail-routing system) will have very low ratios). \\\n",
    "As of 12/23 I'm realzing that I'll need to start with a complete list of all ZIP codes (from USPS) before I start this so I can get a good sense of completeness. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847f9750",
   "metadata": {},
   "source": [
    "Below, I'm reading in that full list of ZIP codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "02309edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ZIP_to_CD_df = pd.read_excel('Data/ZIP_CD_062020.xlsx')\n",
    "\n",
    "ZIP_to_CD_df = ZIP_to_CD_df.rename(columns={\n",
    "    'RES_RATIO': 'CD_RES_RATIO',\n",
    "    'BUS_RATIO': 'CD_BUS_RATIO',\n",
    "    'OTH_RATIO': 'CD_OTH_RATIO',\n",
    "    'TOT_RATIO': 'CD_TOT_RATIO'\n",
    "})\n",
    "\n",
    "ZIP_to_CD_df['ZIP'] = ZIP_to_CD_df['ZIP'].astype(str).str.zfill(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "faf9b462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49649\n",
      "37714\n",
      "     ZIP USPS_STATE             TYPE\n",
      "0  01001         MA  Standard/PO BOX\n",
      "1  01002         MA  Standard/PO BOX\n",
      "2  01004         MA  Standard/PO BOX\n",
      "3  01005         MA  Standard/PO BOX\n",
      "4  01007         MA  Standard/PO BOX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrissoria/anaconda3/lib/python3.11/site-packages/openpyxl/worksheet/header_footer.py:48: UserWarning: Cannot parse header or footer so it will be ignored\n",
      "  warn(\"\"\"Cannot parse header or footer so it will be ignored\"\"\")\n"
     ]
    }
   ],
   "source": [
    "col_types = {\n",
    "    'DELIVERY ZIPCODE': str\n",
    "}\n",
    "\n",
    "FULL_ZIPS = pd.read_excel('Data/Full_Zips.xlsx', dtype=col_types)\n",
    "\n",
    "print(len(FULL_ZIPS))\n",
    "\n",
    "FULL_ZIPS = FULL_ZIPS[['DELIVERY ZIPCODE','PHYSICAL STATE','TYPE']]\n",
    "\n",
    "FULL_ZIPS = FULL_ZIPS.rename(columns={\n",
    "    'DELIVERY ZIPCODE': 'ZIP',\n",
    "    'PHYSICAL STATE': 'USPS_STATE'\n",
    "})\n",
    "\n",
    "#removing ZIP codes that aren't in US main\n",
    "FULL_ZIPS = FULL_ZIPS.drop_duplicates(subset='ZIP', keep='first')\n",
    "FULL_ZIPS['ZIP'] = FULL_ZIPS['ZIP'].astype(str).str.zfill(5)\n",
    "FULL_ZIPS = FULL_ZIPS[pd.notna(FULL_ZIPS['USPS_STATE'])].reset_index(drop=True)\n",
    "exclude_states = [\"VI\", \"PR\", \"MH\", \"MP\", \"FM\", \"GU\"]\n",
    "FULL_ZIPS = FULL_ZIPS[~FULL_ZIPS['USPS_STATE'].isin(exclude_states)].reset_index(drop=True)\n",
    "FULL_ZIPS = FULL_ZIPS[~FULL_ZIPS['TYPE'].isin([\"Other\", \"Unique\"])].reset_index(drop=True)\n",
    "\n",
    "print(len(FULL_ZIPS))\n",
    "print(FULL_ZIPS.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906ffa5e",
   "metadata": {},
   "source": [
    "After merging, I find that many of the Alaska ZIP codes aren't getting matched. Since there's only one CD in Alaska, I'll fill in any Alaska state ZIP with 0200. \\\n",
    "This data will not match PO boxes. Most non matches are coming from PO boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "06e1d800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZIP</th>\n",
       "      <th>USPS_STATE</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>CD</th>\n",
       "      <th>CD_RES_RATIO</th>\n",
       "      <th>CD_BUS_RATIO</th>\n",
       "      <th>CD_OTH_RATIO</th>\n",
       "      <th>CD_TOT_RATIO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01001</td>\n",
       "      <td>MA</td>\n",
       "      <td>Standard/PO BOX</td>\n",
       "      <td>2501</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01002</td>\n",
       "      <td>MA</td>\n",
       "      <td>Standard/PO BOX</td>\n",
       "      <td>2502</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01004</td>\n",
       "      <td>MA</td>\n",
       "      <td>Standard/PO BOX</td>\n",
       "      <td>2502</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01005</td>\n",
       "      <td>MA</td>\n",
       "      <td>Standard/PO BOX</td>\n",
       "      <td>2502</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01007</td>\n",
       "      <td>MA</td>\n",
       "      <td>Standard/PO BOX</td>\n",
       "      <td>2502</td>\n",
       "      <td>0.998118</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44276</th>\n",
       "      <td>99925</td>\n",
       "      <td>AK</td>\n",
       "      <td>Standard/PO BOX</td>\n",
       "      <td>0200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44277</th>\n",
       "      <td>99926</td>\n",
       "      <td>AK</td>\n",
       "      <td>Standard/PO BOX</td>\n",
       "      <td>0200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44278</th>\n",
       "      <td>99927</td>\n",
       "      <td>AK</td>\n",
       "      <td>Standard/PO BOX</td>\n",
       "      <td>0200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44279</th>\n",
       "      <td>99928</td>\n",
       "      <td>AK</td>\n",
       "      <td>Standard/PO BOX</td>\n",
       "      <td>0200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44280</th>\n",
       "      <td>99929</td>\n",
       "      <td>AK</td>\n",
       "      <td>Standard/PO BOX</td>\n",
       "      <td>0200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44281 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ZIP USPS_STATE             TYPE    CD  CD_RES_RATIO  CD_BUS_RATIO  \\\n",
       "0      01001         MA  Standard/PO BOX  2501      1.000000           1.0   \n",
       "1      01002         MA  Standard/PO BOX  2502      1.000000           1.0   \n",
       "2      01004         MA  Standard/PO BOX  2502      1.000000           1.0   \n",
       "3      01005         MA  Standard/PO BOX  2502      1.000000           1.0   \n",
       "4      01007         MA  Standard/PO BOX  2502      0.998118           1.0   \n",
       "...      ...        ...              ...   ...           ...           ...   \n",
       "44276  99925         AK  Standard/PO BOX  0200      0.000000           0.0   \n",
       "44277  99926         AK  Standard/PO BOX  0200      0.000000           0.0   \n",
       "44278  99927         AK  Standard/PO BOX  0200      0.000000           0.0   \n",
       "44279  99928         AK  Standard/PO BOX  0200      0.000000           0.0   \n",
       "44280  99929         AK  Standard/PO BOX  0200      0.000000           0.0   \n",
       "\n",
       "       CD_OTH_RATIO  CD_TOT_RATIO  \n",
       "0               1.0      1.000000  \n",
       "1               1.0      1.000000  \n",
       "2               1.0      1.000000  \n",
       "3               1.0      1.000000  \n",
       "4               1.0      0.998217  \n",
       "...             ...           ...  \n",
       "44276           1.0      1.000000  \n",
       "44277           1.0      1.000000  \n",
       "44278           1.0      1.000000  \n",
       "44279           1.0      1.000000  \n",
       "44280           1.0      1.000000  \n",
       "\n",
       "[44281 rows x 8 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ZIP_FEATURES = pd.merge(FULL_ZIPS, ZIP_to_CD_df, on = \"ZIP\", how = \"left\") #merging to full zips here\n",
    "\n",
    "ZIP_FEATURES['CD'] = ZIP_FEATURES.apply(lambda row: \"0200\" if row['USPS_STATE'] == \"AK\" else row['CD'], axis = 1)\n",
    "ZIP_FEATURES['CD_TOT_RATIO'] = ZIP_FEATURES.apply(lambda row: 1.0 if row['USPS_STATE'] == \"AK\" else row['CD_TOT_RATIO'], axis = 1)\n",
    "\n",
    "ZIP_FEATURES['CD'] = ZIP_FEATURES.apply(lambda row: \"4212\" if row['ZIP'] == \"15253\" else row['CD'],\n",
    "                                       axis=1)\n",
    "\n",
    "ZIP_FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed36d26",
   "metadata": {},
   "source": [
    "For now, I will assign a ZIP code to whatever whatever County it falls mostly under residentially \\\n",
    "This will NOT include DC simply because DC doesn't have a CD \\\n",
    "IN A FUTURE VERSION, I WILL HAVE TO START WITH A LIST OF ZIP CODES THAT INCLUDE DISTRICT OF COLUMBIA'S (WHICH I  HAVE ABOVE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c89f7a",
   "metadata": {},
   "source": [
    "I'm running this as an outer match because then I can keep zip codes from the right side that aren't in the left side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "61dc7c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ZIP COUNTY  RES_RATIO  BUS_RATIO  OTH_RATIO  TOT_RATIO\n",
      "0  00501  36103   0.000000   1.000000   0.000000   1.000000\n",
      "1  00601  72113   0.160758   0.199017   0.128834   0.162397\n",
      "2  00601  72001   0.839242   0.800983   0.871166   0.837603\n",
      "3  00602  72003   1.000000   0.998801   1.000000   0.999919\n",
      "4  00602  72005   0.000000   0.001199   0.000000   0.000081\n",
      "         ZIP USPS_STATE             TYPE    CD  CD_RES_RATIO  CD_BUS_RATIO  \\\n",
      "0      01001         MA  Standard/PO BOX  2501           1.0           1.0   \n",
      "28914  45729         OH  Standard/PO BOX  3906           1.0           1.0   \n",
      "28955  45771         OH  Standard/PO BOX  3906           1.0           1.0   \n",
      "28954  45770         OH  Standard/PO BOX  3906           1.0           1.0   \n",
      "28953  45769         OH  Standard/PO BOX  3906           1.0           1.0   \n",
      "\n",
      "       CD_OTH_RATIO  CD_TOT_RATIO COUNTY  RES_RATIO  BUS_RATIO  OTH_RATIO  \\\n",
      "0               1.0           1.0  25013        1.0        1.0        1.0   \n",
      "28914           1.0           1.0  39167        1.0        1.0        1.0   \n",
      "28955           1.0           1.0  39105        1.0        1.0        1.0   \n",
      "28954           0.0           1.0  39105        1.0        1.0        0.0   \n",
      "28953           1.0           1.0  39105        1.0        1.0        1.0   \n",
      "\n",
      "       TOT_RATIO  \n",
      "0            1.0  \n",
      "28914        1.0  \n",
      "28955        1.0  \n",
      "28954        1.0  \n",
      "28953        1.0  \n",
      "464\n",
      "1.1622955336790162\n"
     ]
    }
   ],
   "source": [
    "col_types = {\n",
    "    'COUNTY': str,\n",
    "    'ZIP': str\n",
    "}\n",
    "\n",
    "ZIP_to_County_df = pd.read_excel('Data/ZIP_COUNTY_062020_HUD.xlsx', dtype=col_types)\n",
    "ZIP_to_County_df['COUNTY'] = ZIP_to_County_df['COUNTY'].astype(str).str.zfill(5)\n",
    "ZIP_to_County_df['ZIP'] = ZIP_to_County_df['ZIP'].astype(str).str.zfill(5)\n",
    "print(ZIP_to_County_df.head())\n",
    "ZIP_FEATURES = pd.merge(ZIP_FEATURES, ZIP_to_County_df, how ='outer', on = \"ZIP\")\n",
    "\n",
    "# Sort the DataFrame by RES_RATIO in descending order\n",
    "ZIP_FEATURES = ZIP_FEATURES.sort_values(by='RES_RATIO', ascending=False)\n",
    "ZIP_FEATURES = ZIP_FEATURES.drop_duplicates(subset='ZIP', keep='first')\n",
    "\n",
    "ZIP_to_County_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "ZIP_to_County_df = ZIP_to_County_df.rename(columns={\n",
    "    'RES_RATIO': 'COUNTY_RES_RATIO',\n",
    "    'BUS_RATIO': 'COUNTY_BUS_RATIO',\n",
    "    'OTH_RATIO': 'COUNTY_OTH_RATIO',\n",
    "    'TOT_RATIO': 'COUNTY_TOT_RATIO'\n",
    "})\n",
    "\n",
    "print(ZIP_FEATURES.head())\n",
    "\n",
    "print(ZIP_FEATURES['COUNTY'].isna().sum()) #high level of match\n",
    "print(ZIP_FEATURES['COUNTY'].isna().mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d8685d",
   "metadata": {},
   "source": [
    "I'm realizing I'll have to merge the school district data onto ZIP_to_County_df (give that there's some zip codes that don't have a school district associated) \\\n",
    "Yet, the issue of some ZIP codes falling through the cracks will still be there. \\\n",
    "I'll need something that goes from county and matches to all ZIP codes within OR \\\n",
    "Something that matches ZIP codes directly to the nearest school district (IDEAL). \\\n",
    "For now (12/26/23) this variable is not complete. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b889c9",
   "metadata": {},
   "source": [
    "Instead, I'll match the ZIP code to a census tract THEN match tract onto school district"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ef1eb603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZIP</th>\n",
       "      <th>USPS_STATE</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>CD</th>\n",
       "      <th>CD_RES_RATIO</th>\n",
       "      <th>CD_BUS_RATIO</th>\n",
       "      <th>CD_OTH_RATIO</th>\n",
       "      <th>CD_TOT_RATIO</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>RES_RATIO_x</th>\n",
       "      <th>BUS_RATIO_x</th>\n",
       "      <th>OTH_RATIO_x</th>\n",
       "      <th>TOT_RATIO_x</th>\n",
       "      <th>TRACT</th>\n",
       "      <th>RES_RATIO_y</th>\n",
       "      <th>BUS_RATIO_y</th>\n",
       "      <th>OTH_RATIO_y</th>\n",
       "      <th>TOT_RATIO_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01001</td>\n",
       "      <td>MA</td>\n",
       "      <td>Standard/PO BOX</td>\n",
       "      <td>2501</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25013813209</td>\n",
       "      <td>0.404431</td>\n",
       "      <td>0.442809</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.403828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45729</td>\n",
       "      <td>OH</td>\n",
       "      <td>Standard/PO BOX</td>\n",
       "      <td>3906</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39167021700</td>\n",
       "      <td>0.752549</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.749772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45771</td>\n",
       "      <td>OH</td>\n",
       "      <td>Standard/PO BOX</td>\n",
       "      <td>3906</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39105</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39105964600</td>\n",
       "      <td>0.793269</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.788959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45770</td>\n",
       "      <td>OH</td>\n",
       "      <td>Standard/PO BOX</td>\n",
       "      <td>3906</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39105</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39105964600</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.924791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45769</td>\n",
       "      <td>OH</td>\n",
       "      <td>Standard/PO BOX</td>\n",
       "      <td>3906</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39105</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39105964200</td>\n",
       "      <td>0.475592</td>\n",
       "      <td>0.139276</td>\n",
       "      <td>0.127660</td>\n",
       "      <td>0.440522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39916</th>\n",
       "      <td>99711</td>\n",
       "      <td>AK</td>\n",
       "      <td>Standard/PO BOX</td>\n",
       "      <td>0200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39917</th>\n",
       "      <td>99716</td>\n",
       "      <td>AK</td>\n",
       "      <td>Standard/PO BOX</td>\n",
       "      <td>0200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39918</th>\n",
       "      <td>99802</td>\n",
       "      <td>AK</td>\n",
       "      <td>Standard/PO BOX</td>\n",
       "      <td>0200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39919</th>\n",
       "      <td>99803</td>\n",
       "      <td>AK</td>\n",
       "      <td>Standard/PO BOX</td>\n",
       "      <td>0200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39920</th>\n",
       "      <td>99821</td>\n",
       "      <td>AK</td>\n",
       "      <td>Standard/PO BOX</td>\n",
       "      <td>0200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39921 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ZIP USPS_STATE             TYPE    CD  CD_RES_RATIO  CD_BUS_RATIO  \\\n",
       "0      01001         MA  Standard/PO BOX  2501           1.0           1.0   \n",
       "1      45729         OH  Standard/PO BOX  3906           1.0           1.0   \n",
       "2      45771         OH  Standard/PO BOX  3906           1.0           1.0   \n",
       "3      45770         OH  Standard/PO BOX  3906           1.0           1.0   \n",
       "4      45769         OH  Standard/PO BOX  3906           1.0           1.0   \n",
       "...      ...        ...              ...   ...           ...           ...   \n",
       "39916  99711         AK  Standard/PO BOX  0200           NaN           NaN   \n",
       "39917  99716         AK  Standard/PO BOX  0200           NaN           NaN   \n",
       "39918  99802         AK  Standard/PO BOX  0200           NaN           NaN   \n",
       "39919  99803         AK  Standard/PO BOX  0200           NaN           NaN   \n",
       "39920  99821         AK  Standard/PO BOX  0200           NaN           NaN   \n",
       "\n",
       "       CD_OTH_RATIO  CD_TOT_RATIO COUNTY  RES_RATIO_x  BUS_RATIO_x  \\\n",
       "0               1.0           1.0  25013          1.0          1.0   \n",
       "1               1.0           1.0  39167          1.0          1.0   \n",
       "2               1.0           1.0  39105          1.0          1.0   \n",
       "3               0.0           1.0  39105          1.0          1.0   \n",
       "4               1.0           1.0  39105          1.0          1.0   \n",
       "...             ...           ...    ...          ...          ...   \n",
       "39916           NaN           1.0    NaN          NaN          NaN   \n",
       "39917           NaN           1.0    NaN          NaN          NaN   \n",
       "39918           NaN           1.0    NaN          NaN          NaN   \n",
       "39919           NaN           1.0    NaN          NaN          NaN   \n",
       "39920           NaN           1.0    NaN          NaN          NaN   \n",
       "\n",
       "       OTH_RATIO_x  TOT_RATIO_x        TRACT  RES_RATIO_y  BUS_RATIO_y  \\\n",
       "0              1.0          1.0  25013813209     0.404431     0.442809   \n",
       "1              1.0          1.0  39167021700     0.752549     0.533333   \n",
       "2              1.0          1.0  39105964600     0.793269     0.693548   \n",
       "3              0.0          1.0  39105964600     0.923077     1.000000   \n",
       "4              1.0          1.0  39105964200     0.475592     0.139276   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "39916          NaN          NaN          NaN          NaN          NaN   \n",
       "39917          NaN          NaN          NaN          NaN          NaN   \n",
       "39918          NaN          NaN          NaN          NaN          NaN   \n",
       "39919          NaN          NaN          NaN          NaN          NaN   \n",
       "39920          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "       OTH_RATIO_y  TOT_RATIO_y  \n",
       "0         0.250000     0.403828  \n",
       "1         1.000000     0.749772  \n",
       "2         0.692308     0.788959  \n",
       "3         0.000000     0.924791  \n",
       "4         0.127660     0.440522  \n",
       "...            ...          ...  \n",
       "39916          NaN          NaN  \n",
       "39917          NaN          NaN  \n",
       "39918          NaN          NaN  \n",
       "39919          NaN          NaN  \n",
       "39920          NaN          NaN  \n",
       "\n",
       "[39921 rows x 18 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_types = {\n",
    "    'TRACT': str,\n",
    "    'ZIP': str\n",
    "}\n",
    "\n",
    "ZIP_to_Tract = pd.read_excel('data/ZIP_TRACT_062020.xlsx', dtype=col_types)\n",
    "\n",
    "ZIP_to_Tract = ZIP_to_Tract.sort_values(by='RES_RATIO', ascending=False)\n",
    "ZIP_to_Tract = ZIP_to_Tract.drop_duplicates(subset='ZIP', keep='first')\n",
    "\n",
    "ZIP_to_Tract.reset_index(drop=True, inplace=True)\n",
    "\n",
    "ZIP_FEATURES = pd.merge(ZIP_FEATURES, ZIP_to_Tract, on = \"ZIP\", how = \"left\")\n",
    "\n",
    "ZIP_FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a55d4d0",
   "metadata": {},
   "source": [
    "Below, I'll read in the county-school district level data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452b15b1",
   "metadata": {},
   "source": [
    "col_types = {\n",
    "    'LEAID': str,\n",
    "    'STCOUNTY': str\n",
    "}\n",
    "\n",
    "County_to_District = pd.read_excel('data/grf20_lea_county.xlsx', dtype=col_types)\n",
    "County_to_District = County_to_District.sort_values(by='LANDAREA', ascending=False)\n",
    "County_to_District = County_to_District.drop_duplicates(subset='STCOUNTY', keep='first')\n",
    "\n",
    "County_to_District = County_to_District.rename(columns={\"STCOUNTY\": \"COUNTY\"})\n",
    "\n",
    "County_to_District = County_to_District[['NAME_LEA20','COUNTY','LEAID']]\n",
    "\n",
    "ZIP_FEATURES = pd.merge(ZIP_FEATURES, County_to_District, on = \"COUNTY\", how = \"left\")\n",
    "\n",
    "ZIP_FEATURES.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09519af",
   "metadata": {},
   "source": [
    "We also want to add data on mask mandates at the county-level in order to catpure \"given that a mask mandatte was or wasn't implementd...partisans contact is...\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3119cf",
   "metadata": {},
   "source": [
    "Next, I'll clean up the data so that we keep only the desired columns, differentiate between the census tract (higher resolution) school district match and the county-level (lower resolution) match. Lastly, I'll create one column for school district based on both of these types of matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ee78b8",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "ZIP_FEATURES = ZIP_FEATURES.rename(columns = {\n",
    "                                   'NAME_LEA20': 'COUNTY_SCH_DISTRICT',\n",
    "                                   'LEAID': 'COUNTY_LEAID'})\n",
    "\n",
    "ZIP_FEATURES.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec3a7ff",
   "metadata": {},
   "source": [
    "NOTE: The school closure data provides best coverage for months after september 2020 to May 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc48f2ed",
   "metadata": {},
   "source": [
    "schools_closures = pd.read_csv('data/District_Monthly_Shares_03.08.23.csv',dtype=str)\n",
    "\n",
    "columns_to_keep = ['NCESDistrictID','month','share_inperson','DistrictName']\n",
    "\n",
    "schools_closures = schools_closures[columns_to_keep]\n",
    "\n",
    "schools_closures['LEAID'] = schools_closures['NCESDistrictID'].apply(lambda x: '00' + x if len(x) == 5 else x)\n",
    "\n",
    "schools_closures['NCESDistrictID'] = schools_closures['LEAID'].apply(lambda x: '0' + x if len(x) == 6 else x)\n",
    "\n",
    "#for mid 2020 (taking two months in case the first is missing August and September)\n",
    "\n",
    "schools_closures_m2020 = schools_closures[schools_closures['month'] == \"2020m8\"].reset_index(drop=True)\n",
    "\n",
    "schools_closures_m2020 = schools_closures_m2020.rename(columns={\n",
    "    'share_inperson': 'august20_school_share_inperson'\n",
    "})\n",
    "\n",
    "schools_closures_m2020 = schools_closures_m2020[['LEAID','august20_school_share_inperson','DistrictName']]\n",
    "\n",
    "#now mnth 9\n",
    "schools_closures_m2020_2 = schools_closures[schools_closures['month'] == \"2020m9\"].reset_index(drop=True)\n",
    "\n",
    "schools_closures_m2020_2 = schools_closures_m2020_2.rename(columns={\n",
    "    'share_inperson': 'september20_school_share_inperson'\n",
    "})\n",
    "\n",
    "schools_closures_m2020_2 = schools_closures_m2020_2[['LEAID','september20_school_share_inperson']]\n",
    "\n",
    "#for month 10 (aggressive capture)\n",
    "\n",
    "schools_closures_m2020_3 = schools_closures[schools_closures['month'] == \"2020m10\"].reset_index(drop=True)\n",
    "\n",
    "schools_closures_m2020_3 = schools_closures_m2020_3.rename(columns={\n",
    "    'share_inperson': 'october20_school_share_inperson'\n",
    "})\n",
    "\n",
    "schools_closures_m2020_3 = schools_closures_m2020_3[['LEAID','october20_school_share_inperson']]\n",
    "\n",
    "#for late 2020\n",
    "\n",
    "schools_closures_l2020 = schools_closures[schools_closures['month'] == \"2020m12\"].reset_index(drop=True)\n",
    "\n",
    "schools_closures_l2020 = schools_closures_l2020.rename(columns={\n",
    "    'share_inperson': 'december20_school_share_inperson'\n",
    "})\n",
    "\n",
    "schools_closures_l2020 = schools_closures_l2020[['LEAID','december20_school_share_inperson']]\n",
    "\n",
    "\n",
    "schools_closures_l2020_2 = schools_closures[schools_closures['month'] == \"2020m11\"].reset_index(drop=True)\n",
    "\n",
    "schools_closures_l2020_2 = schools_closures_l2020_2.rename(columns={\n",
    "    'share_inperson': 'november20_school_share_inperson'\n",
    "})\n",
    "\n",
    "schools_closures_l2020_2 = schools_closures_l2020_2[['LEAID','november20_school_share_inperson']]\n",
    "\n",
    "\n",
    "#for mid 2021\n",
    "\n",
    "schools_closures_m2021 = schools_closures[schools_closures['month'] == \"2021m3\"].reset_index(drop=True)\n",
    "\n",
    "schools_closures_m2021 = schools_closures_m2021.rename(columns={\n",
    "    'share_inperson': 'march21_school_share_inperson'\n",
    "})\n",
    "\n",
    "schools_closures_m2021 = schools_closures_m2021[['LEAID','march21_school_share_inperson']]\n",
    "\n",
    "\n",
    "schools_closures_m2021_2 = schools_closures[schools_closures['month'] == \"2021m2\"].reset_index(drop=True)\n",
    "\n",
    "schools_closures_m2021_2 = schools_closures_m2021_2.rename(columns={\n",
    "    'share_inperson': 'feb21_school_share_inperson'\n",
    "})\n",
    "\n",
    "schools_closures_m2021_2 = schools_closures_m2021_2[['LEAID','feb21_school_share_inperson']]\n",
    "\n",
    "#later mid 2021\n",
    "\n",
    "schools_closures_lm2021 = schools_closures[schools_closures['month'] == \"2021m4\"].reset_index(drop=True)\n",
    "\n",
    "schools_closures_lm2021 = schools_closures_lm2021.rename(columns={\n",
    "    'share_inperson': 'april21_school_share_inperson'\n",
    "})\n",
    "\n",
    "schools_closures_lm2021 = schools_closures_lm2021[['LEAID','april21_school_share_inperson']]\n",
    "\n",
    "\n",
    "schools_closures_lm2021_2 = schools_closures[schools_closures['month'] == \"2021m5\"].reset_index(drop=True)\n",
    "\n",
    "schools_closures_lm2021_2 = schools_closures_lm2021_2.rename(columns={\n",
    "    'share_inperson': 'may21_school_share_inperson'\n",
    "})\n",
    "\n",
    "schools_closures_lm2021_2 = schools_closures_lm2021_2[['LEAID','may21_school_share_inperson']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caeddc33",
   "metadata": {},
   "source": [
    "Early fall = Aug-Oct\n",
    "Fall 2020 = Nov-Dec\n",
    "Spring 2021 = Feb-Mar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e65e36",
   "metadata": {},
   "source": [
    "schools_closures = schools_closures[~schools_closures['LEAID'].duplicated()]\n",
    "\n",
    "schools_closures = pd.merge(schools_closures, schools_closures_m2020, how = 'left', on = 'LEAID')\n",
    "schools_closures = pd.merge(schools_closures, schools_closures_m2020_2, how = 'left', on = 'LEAID')\n",
    "schools_closures = pd.merge(schools_closures, schools_closures_m2020_3, how = 'left', on = 'LEAID')\n",
    "schools_closures = pd.merge(schools_closures, schools_closures_l2020_2, how = 'left', on = 'LEAID')\n",
    "schools_closures = pd.merge(schools_closures, schools_closures_l2020, how = 'left', on = 'LEAID')\n",
    "schools_closures = pd.merge(schools_closures, schools_closures_m2021_2, how = 'left', on = 'LEAID')\n",
    "schools_closures = pd.merge(schools_closures, schools_closures_m2021, how = 'left', on = 'LEAID')\n",
    "schools_closures = pd.merge(schools_closures, schools_closures_lm2021_2, how = 'left', on = 'LEAID')\n",
    "schools_closures = pd.merge(schools_closures, schools_closures_lm2021, how = 'left', on = 'LEAID')\n",
    "\n",
    "#aug, sept, oct (2020)\n",
    "schools_closures['earlyfall2020_school_closures'] = schools_closures.apply(\n",
    "    lambda row: row['september20_school_share_inperson'] if pd.isna(row['august20_school_share_inperson']) else row['august20_school_share_inperson'], \n",
    "    axis=1\n",
    ")\n",
    "schools_closures['earlyfall2020_school_closures'] = schools_closures.apply(\n",
    "    lambda row: row['october20_school_share_inperson'] if pd.isna(row['earlyfall2020_school_closures']) else row['earlyfall2020_school_closures'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "#nov, dec (2020)\n",
    "schools_closures['fall2020_school_closures'] = schools_closures.apply(\n",
    "    lambda row: row['november20_school_share_inperson'] if pd.isna(row['december20_school_share_inperson']) else row['december20_school_share_inperson'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "#feb, march (2021)\n",
    "schools_closures['earlyspring2021_school_closures'] = schools_closures.apply(\n",
    "    lambda row: row['feb21_school_share_inperson'] if pd.isna(row['march21_school_share_inperson']) else row['march21_school_share_inperson'], \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "#april, may (2021)\n",
    "\n",
    "schools_closures['spring2021_school_closures'] = schools_closures.apply(\n",
    "    lambda row: row['april21_school_share_inperson'] if pd.isna(row['may21_school_share_inperson']) else row['may21_school_share_inperson'], \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "schools_closures = schools_closures[['LEAID','earlyfall2020_school_closures','fall2020_school_closures',\n",
    "                                     'earlyspring2021_school_closures','spring2021_school_closures',]]\n",
    "schools_closures.to_csv('data/school_closure_merged.csv')\n",
    "\n",
    "schools_closures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84eb6e78",
   "metadata": {},
   "source": [
    "let's take a look at coverage. Based on these missing counts, it looks like the best coverage available is for fall 2020, with early spring 2021 and late spring 2021 having a higher percentage of missingness (almost 10 percent of rows contain missing data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f3ec2c",
   "metadata": {},
   "source": [
    "na_counts = schools_closures[['LEAID', 'earlyfall2020_school_closures', 'fall2020_school_closures',\n",
    "                              'earlyspring2021_school_closures', 'spring2021_school_closures']].isna().sum()\n",
    "\n",
    "na_percentage = schools_closures[['LEAID', 'earlyfall2020_school_closures', 'fall2020_school_closures',\n",
    "                                  'earlyspring2021_school_closures', 'spring2021_school_closures']].isna().mean() * 100\n",
    "\n",
    "\n",
    "print(na_counts)\n",
    "print(na_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39a92c0",
   "metadata": {},
   "source": [
    "ZIP_FEATURES['LEAID'] = ZIP_FEATURES['LEAID'].astype(str)\n",
    "\n",
    "ZIP_FEATURES['LEAID'] = ZIP_FEATURES['LEAID'].apply(lambda x: '00' + x if len(x) == 5 else x)\n",
    "ZIP_FEATURES['LEAID'] = ZIP_FEATURES['LEAID'].apply(lambda x: '0' + x if len(x) == 6 else x)\n",
    "\n",
    "schools_closures['LEAID'] = schools_closures['LEAID'].apply(lambda x: '00' + x if len(x) == 5 else x)\n",
    "schools_closures['LEAID'] = schools_closures['LEAID'].apply(lambda x: '0' + x if len(x) == 6 else x)\n",
    "\n",
    "ZIP_FEATURES = pd.merge(ZIP_FEATURES, schools_closures, how = 'left', on = \"LEAID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f14d43",
   "metadata": {},
   "source": [
    "In terms of ZIP codes, this translates to big percentages. Over 20% of zip codes do not have data on school closures for the spring 2021 semester."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6a38f8",
   "metadata": {},
   "source": [
    "na_counts = ZIP_FEATURES[['LEAID', 'earlyfall2020_school_closures', 'fall2020_school_closures',\n",
    "                              'earlyspring2021_school_closures', 'spring2021_school_closures']].isna().sum()\n",
    "\n",
    "na_percentage = ZIP_FEATURES[['LEAID', 'earlyfall2020_school_closures', 'fall2020_school_closures',\n",
    "                                  'earlyspring2021_school_closures', 'spring2021_school_closures']].isna().mean() * 100\n",
    "\n",
    "\n",
    "print(na_counts)\n",
    "print(na_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37ca30f",
   "metadata": {},
   "source": [
    "I tried to consolidate the 2021 semester category for better coverage, but it made no difference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d6b2ee",
   "metadata": {},
   "source": [
    "Maybe it doesn't make sense to have ZIP to CD and ZIP to County in the same dataset. I might make these into two later on, but for now this contains the county under which the ZIP code mostly falls for residential addresses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a04631d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_types = {\n",
    "    'FIPS_Code': str,\n",
    "    'District': str,\n",
    "    'CD':str\n",
    "}\n",
    "\n",
    "CD_df = pd.read_csv('data/House_Reps_District.csv', dtype=col_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a844a873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZIP</th>\n",
       "      <th>USPS_STATE</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>CD_BUS_RATIO</th>\n",
       "      <th>CD_OTH_RATIO</th>\n",
       "      <th>CD_TOT_RATIO</th>\n",
       "      <th>COUNTY_FIPS</th>\n",
       "      <th>RES_RATIO_x</th>\n",
       "      <th>BUS_RATIO_x</th>\n",
       "      <th>OTH_RATIO_x</th>\n",
       "      <th>...</th>\n",
       "      <th>OTH_RATIO_y</th>\n",
       "      <th>TOT_RATIO_y</th>\n",
       "      <th>CONGRESSPERSON</th>\n",
       "      <th>STATE</th>\n",
       "      <th>District</th>\n",
       "      <th>CONGRESSPERSON_PARTY</th>\n",
       "      <th>Years_Served</th>\n",
       "      <th>FIPS_Code</th>\n",
       "      <th>CD</th>\n",
       "      <th>CD_RES_RATIO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01001</td>\n",
       "      <td>MA</td>\n",
       "      <td>Standard/PO BOX</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.403828</td>\n",
       "      <td>Neal, Richard E.</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>01</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>House: 1989-Present</td>\n",
       "      <td>25</td>\n",
       "      <td>2501</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45729</td>\n",
       "      <td>OH</td>\n",
       "      <td>Standard/PO BOX</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.749772</td>\n",
       "      <td>Johnson, Bill</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>06</td>\n",
       "      <td>Republican</td>\n",
       "      <td>House: 2011-Present</td>\n",
       "      <td>39</td>\n",
       "      <td>3906</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45771</td>\n",
       "      <td>OH</td>\n",
       "      <td>Standard/PO BOX</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39105</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.788959</td>\n",
       "      <td>Johnson, Bill</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>06</td>\n",
       "      <td>Republican</td>\n",
       "      <td>House: 2011-Present</td>\n",
       "      <td>39</td>\n",
       "      <td>3906</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45770</td>\n",
       "      <td>OH</td>\n",
       "      <td>Standard/PO BOX</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39105</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.924791</td>\n",
       "      <td>Johnson, Bill</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>06</td>\n",
       "      <td>Republican</td>\n",
       "      <td>House: 2011-Present</td>\n",
       "      <td>39</td>\n",
       "      <td>3906</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45769</td>\n",
       "      <td>OH</td>\n",
       "      <td>Standard/PO BOX</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39105</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127660</td>\n",
       "      <td>0.440522</td>\n",
       "      <td>Johnson, Bill</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>06</td>\n",
       "      <td>Republican</td>\n",
       "      <td>House: 2011-Present</td>\n",
       "      <td>39</td>\n",
       "      <td>3906</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40766</th>\n",
       "      <td>99711</td>\n",
       "      <td>AK</td>\n",
       "      <td>Standard/PO BOX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Young, Don</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>00</td>\n",
       "      <td>Republican</td>\n",
       "      <td>House: 1973-2022</td>\n",
       "      <td>02</td>\n",
       "      <td>0200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40767</th>\n",
       "      <td>99716</td>\n",
       "      <td>AK</td>\n",
       "      <td>Standard/PO BOX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Young, Don</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>00</td>\n",
       "      <td>Republican</td>\n",
       "      <td>House: 1973-2022</td>\n",
       "      <td>02</td>\n",
       "      <td>0200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40768</th>\n",
       "      <td>99802</td>\n",
       "      <td>AK</td>\n",
       "      <td>Standard/PO BOX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Young, Don</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>00</td>\n",
       "      <td>Republican</td>\n",
       "      <td>House: 1973-2022</td>\n",
       "      <td>02</td>\n",
       "      <td>0200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40769</th>\n",
       "      <td>99803</td>\n",
       "      <td>AK</td>\n",
       "      <td>Standard/PO BOX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Young, Don</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>00</td>\n",
       "      <td>Republican</td>\n",
       "      <td>House: 1973-2022</td>\n",
       "      <td>02</td>\n",
       "      <td>0200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40770</th>\n",
       "      <td>99821</td>\n",
       "      <td>AK</td>\n",
       "      <td>Standard/PO BOX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Young, Don</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>00</td>\n",
       "      <td>Republican</td>\n",
       "      <td>House: 1973-2022</td>\n",
       "      <td>02</td>\n",
       "      <td>0200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40771 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ZIP USPS_STATE             TYPE  CD_BUS_RATIO  CD_OTH_RATIO  \\\n",
       "0      01001         MA  Standard/PO BOX           1.0           1.0   \n",
       "1      45729         OH  Standard/PO BOX           1.0           1.0   \n",
       "2      45771         OH  Standard/PO BOX           1.0           1.0   \n",
       "3      45770         OH  Standard/PO BOX           1.0           0.0   \n",
       "4      45769         OH  Standard/PO BOX           1.0           1.0   \n",
       "...      ...        ...              ...           ...           ...   \n",
       "40766  99711         AK  Standard/PO BOX           NaN           NaN   \n",
       "40767  99716         AK  Standard/PO BOX           NaN           NaN   \n",
       "40768  99802         AK  Standard/PO BOX           NaN           NaN   \n",
       "40769  99803         AK  Standard/PO BOX           NaN           NaN   \n",
       "40770  99821         AK  Standard/PO BOX           NaN           NaN   \n",
       "\n",
       "       CD_TOT_RATIO COUNTY_FIPS  RES_RATIO_x  BUS_RATIO_x  OTH_RATIO_x  ...  \\\n",
       "0               1.0       25013          1.0          1.0          1.0  ...   \n",
       "1               1.0       39167          1.0          1.0          1.0  ...   \n",
       "2               1.0       39105          1.0          1.0          1.0  ...   \n",
       "3               1.0       39105          1.0          1.0          0.0  ...   \n",
       "4               1.0       39105          1.0          1.0          1.0  ...   \n",
       "...             ...         ...          ...          ...          ...  ...   \n",
       "40766           1.0         NaN          NaN          NaN          NaN  ...   \n",
       "40767           1.0         NaN          NaN          NaN          NaN  ...   \n",
       "40768           1.0         NaN          NaN          NaN          NaN  ...   \n",
       "40769           1.0         NaN          NaN          NaN          NaN  ...   \n",
       "40770           1.0         NaN          NaN          NaN          NaN  ...   \n",
       "\n",
       "       OTH_RATIO_y TOT_RATIO_y    CONGRESSPERSON          STATE  District  \\\n",
       "0         0.250000    0.403828  Neal, Richard E.  Massachusetts        01   \n",
       "1         1.000000    0.749772     Johnson, Bill           Ohio        06   \n",
       "2         0.692308    0.788959     Johnson, Bill           Ohio        06   \n",
       "3         0.000000    0.924791     Johnson, Bill           Ohio        06   \n",
       "4         0.127660    0.440522     Johnson, Bill           Ohio        06   \n",
       "...            ...         ...               ...            ...       ...   \n",
       "40766          NaN         NaN        Young, Don         Alaska        00   \n",
       "40767          NaN         NaN        Young, Don         Alaska        00   \n",
       "40768          NaN         NaN        Young, Don         Alaska        00   \n",
       "40769          NaN         NaN        Young, Don         Alaska        00   \n",
       "40770          NaN         NaN        Young, Don         Alaska        00   \n",
       "\n",
       "       CONGRESSPERSON_PARTY         Years_Served FIPS_Code    CD CD_RES_RATIO  \n",
       "0                Democratic  House: 1989-Present        25  2501          1.0  \n",
       "1                Republican  House: 2011-Present        39  3906          1.0  \n",
       "2                Republican  House: 2011-Present        39  3906          1.0  \n",
       "3                Republican  House: 2011-Present        39  3906          1.0  \n",
       "4                Republican  House: 2011-Present        39  3906          1.0  \n",
       "...                     ...                  ...       ...   ...          ...  \n",
       "40766            Republican     House: 1973-2022        02  0200          NaN  \n",
       "40767            Republican     House: 1973-2022        02  0200          NaN  \n",
       "40768            Republican     House: 1973-2022        02  0200          NaN  \n",
       "40769            Republican     House: 1973-2022        02  0200          NaN  \n",
       "40770            Republican     House: 1973-2022        02  0200          NaN  \n",
       "\n",
       "[40771 rows x 24 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ZIP_FEATURES['CD'] = ZIP_FEATURES['CD'].astype(str)\n",
    "CD_df['CD'] = CD_df['CD'].astype(str)\n",
    "\n",
    "\n",
    "ZIP_FEATURES = pd.merge(ZIP_FEATURES, CD_df, on = \"CD\", how= \"left\")\n",
    "\n",
    "ZIP_FEATURES = ZIP_FEATURES.rename(columns={\n",
    "    'COUNTY': 'COUNTY_FIPS', #coming from the HUD ZIP to County DF\n",
    "    'Name': 'CONGRESSPERSON',\n",
    "    'State': 'STATE',\n",
    "    'Party': 'CONGRESSPERSON_PARTY'\n",
    "})\n",
    "\n",
    "cols_to_move = ZIP_FEATURES.columns[3:5]\n",
    "df_remaining = ZIP_FEATURES.drop(columns=cols_to_move)\n",
    "ZIP_FEATURES = pd.concat([df_remaining, ZIP_FEATURES[cols_to_move]], axis=1)\n",
    "\n",
    "ZIP_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3826a0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  COUNTY_FIPS  county_conditions   state_conditions\n",
      "0       01067  all public places  all public places\n",
      "1       01071  all public places  all public places\n",
      "2       01093        retail only  all public places\n",
      "3       01073  all public places  all public places\n",
      "4       01099  all public places  all public places\n",
      "     ZIP USPS_STATE             TYPE  CD_BUS_RATIO  CD_OTH_RATIO  \\\n",
      "0  01001         MA  Standard/PO BOX           1.0           1.0   \n",
      "1  45729         OH  Standard/PO BOX           1.0           1.0   \n",
      "2  45771         OH  Standard/PO BOX           1.0           1.0   \n",
      "3  45770         OH  Standard/PO BOX           1.0           0.0   \n",
      "4  45769         OH  Standard/PO BOX           1.0           1.0   \n",
      "\n",
      "   CD_TOT_RATIO COUNTY_FIPS  RES_RATIO_x  BUS_RATIO_x  OTH_RATIO_x  ...  \\\n",
      "0           1.0       25013          1.0          1.0          1.0  ...   \n",
      "1           1.0       39167          1.0          1.0          1.0  ...   \n",
      "2           1.0       39105          1.0          1.0          1.0  ...   \n",
      "3           1.0       39105          1.0          1.0          0.0  ...   \n",
      "4           1.0       39105          1.0          1.0          1.0  ...   \n",
      "\n",
      "     CONGRESSPERSON          STATE  District  CONGRESSPERSON_PARTY  \\\n",
      "0  Neal, Richard E.  Massachusetts        01            Democratic   \n",
      "1     Johnson, Bill           Ohio        06            Republican   \n",
      "2     Johnson, Bill           Ohio        06            Republican   \n",
      "3     Johnson, Bill           Ohio        06            Republican   \n",
      "4     Johnson, Bill           Ohio        06            Republican   \n",
      "\n",
      "          Years_Served  FIPS_Code    CD CD_RES_RATIO  county_conditions  \\\n",
      "0  House: 1989-Present         25  2501          1.0  all public places   \n",
      "1  House: 2011-Present         39  3906          1.0  all public places   \n",
      "2  House: 2011-Present         39  3906          1.0  all public places   \n",
      "3  House: 2011-Present         39  3906          1.0  all public places   \n",
      "4  House: 2011-Present         39  3906          1.0  all public places   \n",
      "\n",
      "                                    state_conditions  \n",
      "0                                      Public places  \n",
      "1  Applies to people age 10 and older when in pub...  \n",
      "2  Applies to people age 10 and older when in pub...  \n",
      "3  Applies to people age 10 and older when in pub...  \n",
      "4  Applies to people age 10 and older when in pub...  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "col_types = {\n",
    "    'county_fips': str\n",
    "}\n",
    "\n",
    "mask_mandates_count = pd.read_excel('data/county_mask_mandate_data.xlsx', dtype=col_types)\n",
    "mask_mandates_count = mask_mandates_count[['county_fips','county_conditions','state_conditions']]\n",
    "\n",
    "mask_mandates_count['county_fips'] = mask_mandates_count['county_fips'].astype(str).str.zfill(5)\n",
    "\n",
    "mask_mandates_count['county_conditions'] = mask_mandates_count.apply(\n",
    "    lambda row: row['state_conditions'] if pd.isna(row['county_conditions']) and not pd.isna(row['state_conditions']) else row['county_conditions'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "mask_mandates_count['county_conditions'] = mask_mandates_count.apply(\n",
    "    lambda row: \"no mandate\" if pd.isna(row['county_conditions']) else row['county_conditions'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "mask_mandates_count = mask_mandates_count.rename(columns = {\n",
    "    'county_fips': 'COUNTY_FIPS'\n",
    "})\n",
    "\n",
    "print(mask_mandates_count.head())\n",
    "\n",
    "ZIP_FEATURES = pd.merge(ZIP_FEATURES, mask_mandates_count, on = \"COUNTY_FIPS\", how= \"left\")\n",
    "\n",
    "print(ZIP_FEATURES.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc99c4a",
   "metadata": {},
   "source": [
    "I have a pretty decent match rate of 95%. However, let's take a look at some of the non-matches and see if we can fill in the gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c649a0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2732\n",
      "6.700841284246155\n"
     ]
    }
   ],
   "source": [
    "print(ZIP_FEATURES['CONGRESSPERSON'].isna().sum())\n",
    "print(ZIP_FEATURES['CONGRESSPERSON'].isna().mean() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2337bc8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "790\n",
      "1.9376517622820142\n"
     ]
    }
   ],
   "source": [
    "print(ZIP_FEATURES['county_conditions'].isna().sum())\n",
    "print(ZIP_FEATURES['county_conditions'].isna().mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d304d05",
   "metadata": {},
   "source": [
    "Below, we need to add a leading \"0\" to the FIPS code (FIPS codes are all 5 digits) \\\n",
    "These are cumulative mortality numbers (not weekly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8bf80201",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_types = {\n",
    "    'countyFIPS': str\n",
    "}\n",
    "\n",
    "usafacts_deaths = pd.read_csv('Data/Partisanship and Health Behavior/Data/covid_deaths_usafacts.csv', dtype=col_types)\n",
    "usafacts_deaths['countyFIPS'] = usafacts_deaths['countyFIPS'].astype(str).str.zfill(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2953de",
   "metadata": {},
   "source": [
    "For this preliminary analysis, I will only use wave 2,4,6. \\\n",
    "Each wave's data was collected on 2020-06-17 - 2020-06-23, 2020-11-29 - 2020-12-16, 2021-05-12 - 2021-05-25. \\\n",
    "I will take covid mortality from the midpoint of the wave range. \\\n",
    "Wave 2 = 6/18-24. 2020 \\\n",
    "Wave 3 = 9/12-20, 2020 \\\n",
    "Wave 4 = 12/1-7, 2020 \\\n",
    "Wave 5 = 2/9-14, 2021 \\\n",
    "Wave 6 = 5/14-25, 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4590cea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNTY_FIPS</th>\n",
       "      <th>County Name</th>\n",
       "      <th>COUNTY_COV_DEATHS_2020_06_01</th>\n",
       "      <th>COUNTY_COV_DEATHS_2020_06_15</th>\n",
       "      <th>COUNTY_COV_DEATHS_2020_06_13</th>\n",
       "      <th>COUNTY_COV_DEATHS_2020_06_20</th>\n",
       "      <th>COUNTY_COV_DEATHS_2020_09_01</th>\n",
       "      <th>COUNTY_COV_DEATHS_2020_09_16</th>\n",
       "      <th>COUNTY_COV_DEATHS_2020_09_09</th>\n",
       "      <th>COUNTY_COV_DEATHS_2020_09_05</th>\n",
       "      <th>...</th>\n",
       "      <th>COUNTY_COV_DEATHS_2020_12_01</th>\n",
       "      <th>COUNTY_COV_DEATHS_2020_11_28</th>\n",
       "      <th>COUNTY_COV_DEATHS_2021_02_12</th>\n",
       "      <th>COUNTY_COV_DEATHS_2021_02_10</th>\n",
       "      <th>COUNTY_COV_DEATHS_2021_02_05</th>\n",
       "      <th>COUNTY_COV_DEATHS_2021_01_29</th>\n",
       "      <th>COUNTY_COV_DEATHS_2021_05_19</th>\n",
       "      <th>COUNTY_COV_DEATHS_2021_05_17</th>\n",
       "      <th>COUNTY_COV_DEATHS_2021_05_12</th>\n",
       "      <th>COUNTY_COV_DEATHS_2021_05_05</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000</td>\n",
       "      <td>Statewide Unallocated</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01001</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>84</td>\n",
       "      <td>79</td>\n",
       "      <td>76</td>\n",
       "      <td>69</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01003</td>\n",
       "      <td>Baldwin County</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>42</td>\n",
       "      <td>47</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>...</td>\n",
       "      <td>137</td>\n",
       "      <td>98</td>\n",
       "      <td>251</td>\n",
       "      <td>239</td>\n",
       "      <td>234</td>\n",
       "      <td>224</td>\n",
       "      <td>310</td>\n",
       "      <td>310</td>\n",
       "      <td>309</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01005</td>\n",
       "      <td>Barbour County</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>48</td>\n",
       "      <td>46</td>\n",
       "      <td>44</td>\n",
       "      <td>40</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01007</td>\n",
       "      <td>Bibb County</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>57</td>\n",
       "      <td>54</td>\n",
       "      <td>52</td>\n",
       "      <td>51</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  COUNTY_FIPS            County Name  COUNTY_COV_DEATHS_2020_06_01  \\\n",
       "0       00000  Statewide Unallocated                             0   \n",
       "1       01001        Autauga County                              5   \n",
       "2       01003        Baldwin County                              9   \n",
       "3       01005        Barbour County                              1   \n",
       "4       01007           Bibb County                              1   \n",
       "\n",
       "   COUNTY_COV_DEATHS_2020_06_15  COUNTY_COV_DEATHS_2020_06_13  \\\n",
       "0                             0                             0   \n",
       "1                             6                             6   \n",
       "2                             9                             9   \n",
       "3                             1                             1   \n",
       "4                             1                             1   \n",
       "\n",
       "   COUNTY_COV_DEATHS_2020_06_20  COUNTY_COV_DEATHS_2020_09_01  \\\n",
       "0                             0                             0   \n",
       "1                             9                            24   \n",
       "2                             9                            42   \n",
       "3                             1                             7   \n",
       "4                             1                             8   \n",
       "\n",
       "   COUNTY_COV_DEATHS_2020_09_16  COUNTY_COV_DEATHS_2020_09_09  \\\n",
       "0                             0                             0   \n",
       "1                            24                            24   \n",
       "2                            47                            46   \n",
       "3                             7                             7   \n",
       "4                             9                             9   \n",
       "\n",
       "   COUNTY_COV_DEATHS_2020_09_05  ...  COUNTY_COV_DEATHS_2020_12_01  \\\n",
       "0                             0  ...                             0   \n",
       "1                            24  ...                            41   \n",
       "2                            46  ...                           137   \n",
       "3                             7  ...                            11   \n",
       "4                             9  ...                            18   \n",
       "\n",
       "   COUNTY_COV_DEATHS_2020_11_28  COUNTY_COV_DEATHS_2021_02_12  \\\n",
       "0                             0                             0   \n",
       "1                            41                            84   \n",
       "2                            98                           251   \n",
       "3                            10                            48   \n",
       "4                            17                            57   \n",
       "\n",
       "   COUNTY_COV_DEATHS_2021_02_10  COUNTY_COV_DEATHS_2021_02_05  \\\n",
       "0                             0                             0   \n",
       "1                            79                            76   \n",
       "2                           239                           234   \n",
       "3                            46                            44   \n",
       "4                            54                            52   \n",
       "\n",
       "   COUNTY_COV_DEATHS_2021_01_29  COUNTY_COV_DEATHS_2021_05_19  \\\n",
       "0                             0                             0   \n",
       "1                            69                           108   \n",
       "2                           224                           310   \n",
       "3                            40                            56   \n",
       "4                            51                            64   \n",
       "\n",
       "   COUNTY_COV_DEATHS_2021_05_17  COUNTY_COV_DEATHS_2021_05_12  \\\n",
       "0                             0                             0   \n",
       "1                           108                           108   \n",
       "2                           310                           309   \n",
       "3                            56                            56   \n",
       "4                            64                            64   \n",
       "\n",
       "   COUNTY_COV_DEATHS_2021_05_05  \n",
       "0                             0  \n",
       "1                           108  \n",
       "2                           307  \n",
       "3                            56  \n",
       "4                            63  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_keep = ['countyFIPS','County Name',\n",
    "                   '2020-06-01','2020-06-15','2020-06-13','2020-06-20', #w2\n",
    "                   '2020-09-01','2020-09-16','2020-09-09','2020-09-05', #w3\n",
    "                   '2020-12-05','2020-12-04','2020-12-01','2020-11-28', #w4\n",
    "                   '2021-02-12','2021-02-10','2021-02-05','2021-01-29', #w5\n",
    "                   '2021-05-19','2021-05-17','2021-05-12','2021-05-05'] #w6\n",
    "\n",
    "usafacts_deaths = usafacts_deaths[columns_to_keep]\n",
    "\n",
    "new_column_names = [col if idx < 2 else 'COUNTY_COV_DEATHS_' + col.replace('-', '_') for idx, col in enumerate(columns_to_keep)]\n",
    "\n",
    "usafacts_deaths.columns = new_column_names\n",
    "\n",
    "usafacts_deaths = usafacts_deaths.rename(columns={\n",
    "    'countyFIPS': 'COUNTY_FIPS'\n",
    "})\n",
    "\n",
    "usafacts_deaths.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c09feb9",
   "metadata": {},
   "source": [
    "Nearly all ZIP codes get a match (less than 1 percent don't get matched). \\\n",
    "If we end up going back to mortality rates (as of now (01/14/24) we're using prevalence rates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4716ac9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664\n",
      "1.6286085698167814\n"
     ]
    }
   ],
   "source": [
    "ZIP_FEATURES = pd.merge(ZIP_FEATURES, usafacts_deaths, on = \"COUNTY_FIPS\", how = \"left\")\n",
    "\n",
    "print(ZIP_FEATURES['COUNTY_COV_DEATHS_2020_06_01'].isna().sum())\n",
    "print(ZIP_FEATURES['COUNTY_COV_DEATHS_2020_06_01'].isna().mean() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "05974d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/89/6bdxzk2j30v5n3wstywbcpg80000gn/T/ipykernel_41031/4051827355.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  State_FIPS_Crosswalk['STATE_FIPS'] = State_FIPS_Crosswalk['STATE'].astype(str)\n",
      "/var/folders/89/6bdxzk2j30v5n3wstywbcpg80000gn/T/ipykernel_41031/4051827355.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  State_FIPS_Crosswalk['STATE'] = State_FIPS_Crosswalk['STNAME']\n"
     ]
    }
   ],
   "source": [
    "col_types1 = {\n",
    "    'STATE': str,\n",
    "    'COUNTY': str\n",
    "}\n",
    "\n",
    "col_types2 = {\n",
    "    'County Code (FIPS)': str,\n",
    "    'County Subdivision Code (FIPS)': str,\n",
    "    'Place Code (FIPS)': str,\n",
    "    'Consolidtated City Code (FIPS)': str,\n",
    "    'State Code (FIPS)': str\n",
    "}\n",
    "\n",
    "\n",
    "census_pop = pd.read_csv('Data/Partisanship and Health Behavior/Data/co-est2021-alldata.csv', encoding='ISO-8859-1',\n",
    "                        dtype = col_types1)\n",
    "census_pop_FIPS = pd.read_excel('Data/Partisanship and Health Behavior/Data/all-geocodes-v2020.xlsx', \n",
    "                                dtype = col_types2)\n",
    "\n",
    "census_pop_FIPS = census_pop_FIPS.rename(columns={\n",
    "    'Area Name (including legal/statistical area description)': 'CTYNAME'\n",
    "})\n",
    "\n",
    "census_pop['COUNTY_FIPS'] = census_pop['STATE']+census_pop['COUNTY']\n",
    "\n",
    "State_FIPS_Crosswalk = census_pop[['STATE','STNAME']]\n",
    "State_FIPS_Crosswalk['STATE_FIPS'] = State_FIPS_Crosswalk['STATE'].astype(str)\n",
    "State_FIPS_Crosswalk['STATE'] = State_FIPS_Crosswalk['STNAME']\n",
    "\n",
    "State_FIPS_Crosswalk = State_FIPS_Crosswalk.drop(columns = ['STNAME'])\n",
    "\n",
    "State_FIPS_Crosswalk = State_FIPS_Crosswalk.drop_duplicates(subset='STATE', keep='first')\n",
    "State_FIPS_Crosswalk = State_FIPS_Crosswalk[pd.notna(State_FIPS_Crosswalk['STATE'])].reset_index(drop=True)\n",
    "\n",
    "State_FIPS_Crosswalk.to_csv('data/STATE_FIPS_CROSSWALK.csv', index = False)\n",
    "State_FIPS_Crosswalk.to_csv('data/Partisanship and Health Behavior/Data/STATE_FIPS_CROSSWALK.csv', index = False)\n",
    "\n",
    "columns_to_keep = ['STATE','POPESTIMATE2020','DEATHS2020','POPESTIMATE2021','DEATHS2021','COUNTY_FIPS']\n",
    "\n",
    "census_pop = census_pop[columns_to_keep]\n",
    "\n",
    "census_pop = census_pop.rename(columns={\n",
    "    'STATE': 'STATE_FIPS'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3ceb2d",
   "metadata": {},
   "source": [
    "A crude mortality rate, not standardized or age adjusted, for this preliminary analysis \\\n",
    "I manually insert Puerto Rico' State FIPS code and District of Columbia to make this a clean merge across the board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e55dc616",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "672\n",
      "1.6482303598145742\n"
     ]
    }
   ],
   "source": [
    "ZIP_FEATURES = pd.merge(ZIP_FEATURES, census_pop, on = \"COUNTY_FIPS\", how = \"left\")\n",
    "\n",
    "\n",
    "ZIP_FEATURES['COV_County_CMR_2020_06_20'] = (ZIP_FEATURES['COUNTY_COV_DEATHS_2020_06_20'] / ZIP_FEATURES['POPESTIMATE2020']) * 1000\n",
    "ZIP_FEATURES['COV_County_CMR_2020_12_09'] = (ZIP_FEATURES['COUNTY_COV_DEATHS_2020_12_05'] / ZIP_FEATURES['POPESTIMATE2020']) * 1000\n",
    "ZIP_FEATURES['COV_County_CMR_2021_05_19'] = (ZIP_FEATURES['COUNTY_COV_DEATHS_2021_05_19'] / ZIP_FEATURES['POPESTIMATE2021']) * 1000\n",
    "ZIP_FEATURES['STATE_FIPS'] = ZIP_FEATURES.apply(lambda row: 72 if row['STATE'] == \"Puerto Rico\" else row['STATE_FIPS'], axis=1)\n",
    "\n",
    "print(ZIP_FEATURES['COV_County_CMR_2020_06_20'].isna().sum())\n",
    "print(ZIP_FEATURES['COV_County_CMR_2020_06_20'].isna().mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e71cd3",
   "metadata": {},
   "source": [
    "We have decided that prevalence is a better measure for predicting contact behavior than mortality \\\n",
    "I want these lags \\\n",
    "Wave 2 (6/18-24, 2020), midpoint: 06/21/2020, lag1: 06/14/2020, lag3: 06/07/2020 \\\n",
    "Wave 3 (9/12-20, 2020), midpoint: 09/16/2020, lag1: 09/09/2020, lag3: 09/02/2020 \\\n",
    "Wave 4 (12/1-7, 2020), midpoint: 12/04/2020, lag1: 11/27/2020, lag3: 11/20/2020 \\\n",
    "Wave 5 (2/9-14, 2021), midpoint: 02/11/2021, lag: 02/04/2021, lag3: 01/28/2021 \\\n",
    "Wave 6 (5/14-25, 2021), midpoint: 05/19/2021, lag: 05/12/2021, lag3: 05/05/2021 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "071b96d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNTY_FIPS</th>\n",
       "      <th>prev_6/21/20</th>\n",
       "      <th>prev_6/18/20</th>\n",
       "      <th>prev_6/14/20</th>\n",
       "      <th>prev_6/7/20</th>\n",
       "      <th>prev_wave_2_incidence</th>\n",
       "      <th>prev_wave_2_inc_week_lag</th>\n",
       "      <th>prev_9/16/20</th>\n",
       "      <th>prev_9/12/20</th>\n",
       "      <th>prev_9/9/20</th>\n",
       "      <th>...</th>\n",
       "      <th>prev_2/4/21</th>\n",
       "      <th>prev_1/28/21</th>\n",
       "      <th>prev_wave_5_incidence</th>\n",
       "      <th>prev_wave_5_inc_week_lag</th>\n",
       "      <th>prev_5/19/21</th>\n",
       "      <th>prev_5/14/21</th>\n",
       "      <th>prev_5/12/21</th>\n",
       "      <th>prev_5/5/21</th>\n",
       "      <th>prev_wave_6_incidence</th>\n",
       "      <th>prev_wave_6_inc_week_lag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01001</td>\n",
       "      <td>428</td>\n",
       "      <td>394</td>\n",
       "      <td>357</td>\n",
       "      <td>265</td>\n",
       "      <td>71</td>\n",
       "      <td>92</td>\n",
       "      <td>1619</td>\n",
       "      <td>1432</td>\n",
       "      <td>1398</td>\n",
       "      <td>...</td>\n",
       "      <td>5811</td>\n",
       "      <td>5554</td>\n",
       "      <td>159</td>\n",
       "      <td>257</td>\n",
       "      <td>7017</td>\n",
       "      <td>6971</td>\n",
       "      <td>6928</td>\n",
       "      <td>6914</td>\n",
       "      <td>89</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01003</td>\n",
       "      <td>415</td>\n",
       "      <td>386</td>\n",
       "      <td>364</td>\n",
       "      <td>313</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>5003</td>\n",
       "      <td>4752</td>\n",
       "      <td>4639</td>\n",
       "      <td>...</td>\n",
       "      <td>18494</td>\n",
       "      <td>17779</td>\n",
       "      <td>466</td>\n",
       "      <td>715</td>\n",
       "      <td>21467</td>\n",
       "      <td>21290</td>\n",
       "      <td>21170</td>\n",
       "      <td>21035</td>\n",
       "      <td>297</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01005</td>\n",
       "      <td>271</td>\n",
       "      <td>262</td>\n",
       "      <td>234</td>\n",
       "      <td>193</td>\n",
       "      <td>37</td>\n",
       "      <td>41</td>\n",
       "      <td>809</td>\n",
       "      <td>620</td>\n",
       "      <td>618</td>\n",
       "      <td>...</td>\n",
       "      <td>1989</td>\n",
       "      <td>1920</td>\n",
       "      <td>41</td>\n",
       "      <td>69</td>\n",
       "      <td>2324</td>\n",
       "      <td>2319</td>\n",
       "      <td>2314</td>\n",
       "      <td>2307</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01007</td>\n",
       "      <td>124</td>\n",
       "      <td>118</td>\n",
       "      <td>104</td>\n",
       "      <td>77</td>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>612</td>\n",
       "      <td>576</td>\n",
       "      <td>564</td>\n",
       "      <td>...</td>\n",
       "      <td>2327</td>\n",
       "      <td>2271</td>\n",
       "      <td>50</td>\n",
       "      <td>56</td>\n",
       "      <td>2652</td>\n",
       "      <td>2630</td>\n",
       "      <td>2612</td>\n",
       "      <td>2604</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01009</td>\n",
       "      <td>146</td>\n",
       "      <td>127</td>\n",
       "      <td>110</td>\n",
       "      <td>72</td>\n",
       "      <td>36</td>\n",
       "      <td>38</td>\n",
       "      <td>1487</td>\n",
       "      <td>1114</td>\n",
       "      <td>1082</td>\n",
       "      <td>...</td>\n",
       "      <td>5842</td>\n",
       "      <td>5612</td>\n",
       "      <td>113</td>\n",
       "      <td>230</td>\n",
       "      <td>6808</td>\n",
       "      <td>6750</td>\n",
       "      <td>6680</td>\n",
       "      <td>6635</td>\n",
       "      <td>128</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103241</th>\n",
       "      <td>00nan</td>\n",
       "      <td>666</td>\n",
       "      <td>588</td>\n",
       "      <td>502</td>\n",
       "      <td>387</td>\n",
       "      <td>164</td>\n",
       "      <td>115</td>\n",
       "      <td>3842</td>\n",
       "      <td>3712</td>\n",
       "      <td>3607</td>\n",
       "      <td>...</td>\n",
       "      <td>26422</td>\n",
       "      <td>25802</td>\n",
       "      <td>479</td>\n",
       "      <td>620</td>\n",
       "      <td>8991</td>\n",
       "      <td>8961</td>\n",
       "      <td>8939</td>\n",
       "      <td>8877</td>\n",
       "      <td>52</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103242</th>\n",
       "      <td>00nan</td>\n",
       "      <td>666</td>\n",
       "      <td>588</td>\n",
       "      <td>502</td>\n",
       "      <td>387</td>\n",
       "      <td>164</td>\n",
       "      <td>115</td>\n",
       "      <td>3842</td>\n",
       "      <td>3712</td>\n",
       "      <td>3607</td>\n",
       "      <td>...</td>\n",
       "      <td>26422</td>\n",
       "      <td>25802</td>\n",
       "      <td>479</td>\n",
       "      <td>620</td>\n",
       "      <td>3552</td>\n",
       "      <td>3536</td>\n",
       "      <td>3516</td>\n",
       "      <td>3483</td>\n",
       "      <td>36</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103243</th>\n",
       "      <td>00nan</td>\n",
       "      <td>666</td>\n",
       "      <td>588</td>\n",
       "      <td>502</td>\n",
       "      <td>387</td>\n",
       "      <td>164</td>\n",
       "      <td>115</td>\n",
       "      <td>3842</td>\n",
       "      <td>3712</td>\n",
       "      <td>3607</td>\n",
       "      <td>...</td>\n",
       "      <td>26422</td>\n",
       "      <td>25802</td>\n",
       "      <td>479</td>\n",
       "      <td>620</td>\n",
       "      <td>29041</td>\n",
       "      <td>28939</td>\n",
       "      <td>28891</td>\n",
       "      <td>28762</td>\n",
       "      <td>150</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103244</th>\n",
       "      <td>00nan</td>\n",
       "      <td>666</td>\n",
       "      <td>588</td>\n",
       "      <td>502</td>\n",
       "      <td>387</td>\n",
       "      <td>164</td>\n",
       "      <td>115</td>\n",
       "      <td>3842</td>\n",
       "      <td>3712</td>\n",
       "      <td>3607</td>\n",
       "      <td>...</td>\n",
       "      <td>26422</td>\n",
       "      <td>25802</td>\n",
       "      <td>479</td>\n",
       "      <td>620</td>\n",
       "      <td>4116</td>\n",
       "      <td>4079</td>\n",
       "      <td>4060</td>\n",
       "      <td>4022</td>\n",
       "      <td>56</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103245</th>\n",
       "      <td>00nan</td>\n",
       "      <td>666</td>\n",
       "      <td>588</td>\n",
       "      <td>502</td>\n",
       "      <td>387</td>\n",
       "      <td>164</td>\n",
       "      <td>115</td>\n",
       "      <td>3842</td>\n",
       "      <td>3712</td>\n",
       "      <td>3607</td>\n",
       "      <td>...</td>\n",
       "      <td>26422</td>\n",
       "      <td>25802</td>\n",
       "      <td>479</td>\n",
       "      <td>620</td>\n",
       "      <td>30565</td>\n",
       "      <td>30421</td>\n",
       "      <td>30334</td>\n",
       "      <td>30121</td>\n",
       "      <td>231</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103246 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       COUNTY_FIPS  prev_6/21/20  prev_6/18/20  prev_6/14/20  prev_6/7/20  \\\n",
       "0            01001           428           394           357          265   \n",
       "1            01003           415           386           364          313   \n",
       "2            01005           271           262           234          193   \n",
       "3            01007           124           118           104           77   \n",
       "4            01009           146           127           110           72   \n",
       "...            ...           ...           ...           ...          ...   \n",
       "103241       00nan           666           588           502          387   \n",
       "103242       00nan           666           588           502          387   \n",
       "103243       00nan           666           588           502          387   \n",
       "103244       00nan           666           588           502          387   \n",
       "103245       00nan           666           588           502          387   \n",
       "\n",
       "        prev_wave_2_incidence  prev_wave_2_inc_week_lag  prev_9/16/20  \\\n",
       "0                          71                        92          1619   \n",
       "1                          51                        51          5003   \n",
       "2                          37                        41           809   \n",
       "3                          20                        27           612   \n",
       "4                          36                        38          1487   \n",
       "...                       ...                       ...           ...   \n",
       "103241                    164                       115          3842   \n",
       "103242                    164                       115          3842   \n",
       "103243                    164                       115          3842   \n",
       "103244                    164                       115          3842   \n",
       "103245                    164                       115          3842   \n",
       "\n",
       "        prev_9/12/20  prev_9/9/20  ...  prev_2/4/21  prev_1/28/21  \\\n",
       "0               1432         1398  ...         5811          5554   \n",
       "1               4752         4639  ...        18494         17779   \n",
       "2                620          618  ...         1989          1920   \n",
       "3                576          564  ...         2327          2271   \n",
       "4               1114         1082  ...         5842          5612   \n",
       "...              ...          ...  ...          ...           ...   \n",
       "103241          3712         3607  ...        26422         25802   \n",
       "103242          3712         3607  ...        26422         25802   \n",
       "103243          3712         3607  ...        26422         25802   \n",
       "103244          3712         3607  ...        26422         25802   \n",
       "103245          3712         3607  ...        26422         25802   \n",
       "\n",
       "        prev_wave_5_incidence  prev_wave_5_inc_week_lag  prev_5/19/21  \\\n",
       "0                         159                       257          7017   \n",
       "1                         466                       715         21467   \n",
       "2                          41                        69          2324   \n",
       "3                          50                        56          2652   \n",
       "4                         113                       230          6808   \n",
       "...                       ...                       ...           ...   \n",
       "103241                    479                       620          8991   \n",
       "103242                    479                       620          3552   \n",
       "103243                    479                       620         29041   \n",
       "103244                    479                       620          4116   \n",
       "103245                    479                       620         30565   \n",
       "\n",
       "        prev_5/14/21  prev_5/12/21  prev_5/5/21  prev_wave_6_incidence  \\\n",
       "0               6971          6928         6914                     89   \n",
       "1              21290         21170        21035                    297   \n",
       "2               2319          2314         2307                     10   \n",
       "3               2630          2612         2604                     40   \n",
       "4               6750          6680         6635                    128   \n",
       "...              ...           ...          ...                    ...   \n",
       "103241          8961          8939         8877                     52   \n",
       "103242          3536          3516         3483                     36   \n",
       "103243         28939         28891        28762                    150   \n",
       "103244          4079          4060         4022                     56   \n",
       "103245         30421         30334        30121                    231   \n",
       "\n",
       "        prev_wave_6_inc_week_lag  \n",
       "0                             14  \n",
       "1                            135  \n",
       "2                              7  \n",
       "3                              8  \n",
       "4                             45  \n",
       "...                          ...  \n",
       "103241                        62  \n",
       "103242                        33  \n",
       "103243                       129  \n",
       "103244                        38  \n",
       "103245                       213  \n",
       "\n",
       "[103246 rows x 31 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_types = {\n",
    "    'FIPS': str,\n",
    "    'iso2':str\n",
    "}\n",
    "\n",
    "\n",
    "prevalence_mid_2020 = pd.read_csv('Data/Partisanship and Health Behavior/Data/JH_Prevalence/time_series_covid19_confirmed_US_mid_2020.csv', \n",
    "                                  dtype = col_types)\n",
    "\n",
    "columns_to_keep = ['FIPS','6/21/20','6/18/20','6/14/20','6/7/20']\n",
    "\n",
    "prevalence_mid_2020 = prevalence_mid_2020[prevalence_mid_2020['iso2'] == 'US']\n",
    "prevalence_mid_2020['FIPS'] = prevalence_mid_2020['FIPS'].apply(lambda x: str(x).rstrip('0').rstrip('.') if pd.notna(x) and '.' in str(x) else x)\n",
    "prevalence_mid_2020['FIPS'] = prevalence_mid_2020['FIPS'].apply(lambda x: str(x).zfill(5))\n",
    "\n",
    "prevalence_mid_2020 = prevalence_mid_2020[columns_to_keep]\n",
    "\n",
    "#06/21/2020 - 06/14/2020\n",
    "prevalence_mid_2020['wave_2_incidence'] = prevalence_mid_2020['6/21/20'] - prevalence_mid_2020['6/14/20']\n",
    "#06/14/2020 - 06/07/2020\n",
    "prevalence_mid_2020['wave_2_inc_week_lag'] = prevalence_mid_2020['6/14/20'] - prevalence_mid_2020['6/7/20']\n",
    "\n",
    "prevalence_mid_2020.to_csv('data/wave_2_incidence.csv', index=False)\n",
    "\n",
    "prevalence_late_2020 =pd.read_csv('Data/Partisanship and Health Behavior/Data/JH_Prevalence/time_series_covid19_confirmed_US_late_2020.csv', \n",
    "                                  dtype = col_types)\n",
    "\n",
    "columns_to_keep = ['FIPS','9/16/20','9/12/20','9/9/20','9/2/20']\n",
    "\n",
    "prevalence_late_2020 = prevalence_late_2020[prevalence_late_2020['iso2'] == 'US']\n",
    "prevalence_late_2020['FIPS'] = prevalence_late_2020['FIPS'].apply(lambda x: str(x).rstrip('0').rstrip('.') if pd.notna(x) and '.' in str(x) else x)\n",
    "prevalence_late_2020['FIPS'] = prevalence_late_2020['FIPS'].apply(lambda x: str(x).zfill(5))\n",
    "\n",
    "prevalence_late_2020 = prevalence_late_2020[columns_to_keep]\n",
    "\n",
    "#09/16/2020 - 09/09/2020\n",
    "prevalence_late_2020['wave_3_incidence'] = prevalence_late_2020['9/16/20'] - prevalence_late_2020['9/9/20']\n",
    "#09/09/2020 - 9/2/2020\n",
    "prevalence_late_2020['wave_3_inc_week_lag'] = prevalence_late_2020['9/9/20'] - prevalence_late_2020['9/2/20']\n",
    "\n",
    "prevalence_late_2020.to_csv('data/wave_3_incidence.csv', index=False)\n",
    "\n",
    "prevalence_early_2021 = pd.read_csv('Data/Partisanship and Health Behavior/Data/JH_Prevalence/time_series_covid19_confirmed_US_early_2021.csv', \n",
    "                                  dtype = col_types)\n",
    "\n",
    "columns_to_keep = ['FIPS','12/4/20','12/1/20','11/27/20','11/20/20']\n",
    "\n",
    "prevalence_early_2021 = prevalence_early_2021[prevalence_early_2021['iso2'] == 'US']\n",
    "prevalence_early_2021['FIPS'] = prevalence_early_2021['FIPS'].apply(lambda x: str(x).rstrip('0').rstrip('.') if pd.notna(x) and '.' in str(x) else x)\n",
    "prevalence_early_2021['FIPS'] = prevalence_early_2021['FIPS'].apply(lambda x: str(x).zfill(5))\n",
    "\n",
    "prevalence_early_2021 = prevalence_early_2021[columns_to_keep]\n",
    "\n",
    "#12/4/20 - 11/27/20\n",
    "prevalence_early_2021['wave_4_incidence'] = prevalence_early_2021['12/4/20'] - prevalence_early_2021['11/27/20']\n",
    "#11/27/20 - 11/20/20\n",
    "prevalence_early_2021['wave_4_inc_week_lag'] = prevalence_early_2021['11/27/20'] - prevalence_early_2021['11/20/20']\n",
    "\n",
    "prevalence_early_2021.to_csv('data/wave_4_incidence.csv', index=False)\n",
    "\n",
    "prevalence_mid_2021 = pd.read_csv('Data/Partisanship and Health Behavior/Data/JH_Prevalence/time_series_covid19_confirmed_US_mid_2021.csv', \n",
    "                                  dtype = col_types)\n",
    "\n",
    "columns_to_keep = ['FIPS','2/11/21','2/9/21','2/4/21','1/28/21']\n",
    "\n",
    "prevalence_mid_2021 = prevalence_mid_2021[prevalence_mid_2021['iso2'] == 'US']\n",
    "prevalence_mid_2021['FIPS'] = prevalence_mid_2021['FIPS'].apply(lambda x: str(x).rstrip('0').rstrip('.') if pd.notna(x) and '.' in str(x) else x)\n",
    "prevalence_mid_2021['FIPS'] = prevalence_mid_2021['FIPS'].apply(lambda x: str(x).zfill(5))\n",
    "\n",
    "prevalence_mid_2021 = prevalence_mid_2021[columns_to_keep]\n",
    "\n",
    "#02/11/2021 - 02/04/2021\n",
    "prevalence_mid_2021['wave_5_incidence'] = prevalence_mid_2021['2/11/21'] - prevalence_mid_2021['2/4/21']\n",
    "#2/4/2021 - 1/28/2021\n",
    "prevalence_mid_2021['wave_5_inc_week_lag'] = prevalence_mid_2021['2/4/21'] - prevalence_mid_2021['1/28/21']\n",
    "\n",
    "prevalence_mid_2021.to_csv('data/wave_5_incidence.csv', index=False)\n",
    "\n",
    "prevalence_mid_2021_2 = pd.read_csv('Data/Partisanship and Health Behavior/Data/JH_Prevalence/time_series_covid19_confirmed_US_mid_2021.csv', \n",
    "                                  dtype = col_types)\n",
    "\n",
    "colums_to_keep = ['FIPS','5/19/21','5/14/21','5/12/21','5/5/21']\n",
    "\n",
    "prevalence_mid_2021_2 = prevalence_mid_2021_2[prevalence_mid_2021_2['iso2'] == 'US']\n",
    "prevalence_mid_2021_2['FIPS'] = prevalence_mid_2021_2['FIPS'].apply(lambda x: str(x).rstrip('0').rstrip('.') if pd.notna(x) and '.' in str(x) else x)\n",
    "prevalence_mid_2021_2['FIPS'] = prevalence_mid_2021_2['FIPS'].apply(lambda x: str(x).zfill(5))\n",
    "\n",
    "prevalence_mid_2021_2 = prevalence_mid_2021_2[colums_to_keep]\n",
    "\n",
    "#05/19/2021 - 05/12/2021\n",
    "prevalence_mid_2021_2['wave_6_incidence'] = prevalence_mid_2021_2['5/19/21'] - prevalence_mid_2021_2['5/12/21']\n",
    "#05/12/2021 - 05/5/2021\n",
    "prevalence_mid_2021_2['wave_6_inc_week_lag'] = prevalence_mid_2021_2['5/12/21'] - prevalence_mid_2021_2['5/5/21']\n",
    "\n",
    "prevalence_mid_2021_2.to_csv('data/wave_6_incidence.csv', index=False)\n",
    "\n",
    "prevalence = pd.merge(prevalence_mid_2020, prevalence_late_2020, how = \"left\", on = \"FIPS\")\n",
    "prevalence = pd.merge(prevalence, prevalence_early_2021, how = \"left\", on = \"FIPS\")\n",
    "prevalence = pd.merge(prevalence, prevalence_mid_2021, how = \"left\", on = \"FIPS\")\n",
    "prevalence = pd.merge(prevalence, prevalence_mid_2021_2, how = 'left', on = \"FIPS\")\n",
    "prevalence.columns = [col if i == 0 else 'prev_' + col for i, col in enumerate(prevalence.columns)]\n",
    "\n",
    "prevalence = prevalence.rename(columns={\n",
    "    'FIPS':'COUNTY_FIPS'\n",
    "})\n",
    "\n",
    "prevalence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893c5873",
   "metadata": {},
   "source": [
    "Next, I want to create the weekly incidence for each key date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f864ba6",
   "metadata": {},
   "source": [
    "#06/21/2020 - 06/14/2020\n",
    "prevalence['wave_2_incidence'] = prevalence['prev_6/21/20'] - prevalence['prev_6/14/20']\n",
    "#09/16/2020 - 09/09/2020\n",
    "prevalence['wave_3_incidence'] = prevalence['prev_9/16/20'] - prevalence['prev_9/9/20']\n",
    "#12/04/2020 - 11/27/2020\n",
    "prevalence['wave_4_incidence'] = prevalence['prev_12/4/20'] - prevalence['prev_11/27/20']\n",
    "#02/11/2021 - 02/04/2021\n",
    "prevalence['wave_5_incidence'] = prevalence['prev_2/11/21'] - prevalence['prev_2/4/21']\n",
    "#05/19/2021 - 05/12/2021\n",
    "prevalence['wave_6_incidence'] = prevalence['prev_5/19/21'] - prevalence['prev_5/12/21']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0c05fa",
   "metadata": {},
   "source": [
    "below we turn these figures into rates based on population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0094a06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "672\n",
      "1.6482303598145742\n"
     ]
    }
   ],
   "source": [
    "ZIP_FEATURES = pd.merge(ZIP_FEATURES, prevalence, on = \"COUNTY_FIPS\", how = \"left\")\n",
    "\n",
    "for col in ZIP_FEATURES.columns:\n",
    "    # Check if the column name starts with 'prev_'\n",
    "    if col.startswith('prev_'):\n",
    "        # Extract the date part of the column name\n",
    "        date_part = col.split('_', 1)[1]\n",
    "        # Perform the calculation and create a new column\n",
    "        ZIP_FEATURES['rate_prev_' + date_part] = (ZIP_FEATURES[col] / ZIP_FEATURES['POPESTIMATE2020']) * 1000\n",
    "        \n",
    "prev_columns = prevalence.columns\n",
    "prev_columns = prev_columns[1:]\n",
    "ZIP_FEATURES = ZIP_FEATURES.drop(columns=prev_columns)\n",
    "\n",
    "print(ZIP_FEATURES['rate_prev_11/27/20'].isna().sum())\n",
    "print(ZIP_FEATURES['rate_prev_11/27/20'].isna().mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643c2496",
   "metadata": {},
   "source": [
    "Below I insert data on urbanicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19fc43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['FIPS','RUCC_2013']\n",
    "\n",
    "col_types = {\n",
    "    'FIPS': str,\n",
    "}\n",
    "\n",
    "RUC_county_df = pd.read_csv('Data/Partisanship and Health Behavior/Data/ruralurbancodes2013.csv', dtype = col_types)\n",
    "\n",
    "RUC_county_df = RUC_county_df[columns_to_keep]\n",
    "\n",
    "RUC_county_df = RUC_county_df.rename(columns={\n",
    "    'RUCC_2013': 'COUNTY_RUCC_2013',\n",
    "    'FIPS':'COUNTY_FIPS'\n",
    "})\n",
    "\n",
    "RUC_county_df['COUNTY_FIPS'] = RUC_county_df['COUNTY_FIPS'].astype(str)\n",
    "\n",
    "ZIP_FEATURES = pd.merge(ZIP_FEATURES, RUC_county_df, on = \"COUNTY_FIPS\", how = \"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd442686",
   "metadata": {},
   "source": [
    "Next, I want to control for the severity of the lockdowns according to Oxford's tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e17cd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "State_Restrictions_df = pd.read_csv('Data/Partisanship and Health Behavior/Data/OxCGRT_USA_differentiated_withnotes_2020.csv')\n",
    "State_Restrictions_df['Date'] = State_Restrictions_df['Date'].astype(str)\n",
    "State_Restrictions_df = State_Restrictions_df[State_Restrictions_df['Date'].isin(['20200617', '20201129'])]\n",
    "columns_to_keep = ['RegionName','GovernmentResponseIndex_SimpleAverage','Date']\n",
    "State_Restrictions_df = State_Restrictions_df[columns_to_keep]\n",
    "\n",
    "State_Restrictions_df = State_Restrictions_df.rename(columns={\n",
    "    'RegionName': 'STATE',\n",
    "    'GovernmentResponseIndex_SimpleAverage':'State_Government_Response_Index'\n",
    "})\n",
    "\n",
    "State_Restrictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b795cae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "State_Restrictions_df['State_Government_Response_Index_06172020'] = State_Restrictions_df.apply(\n",
    "    lambda row: row['State_Government_Response_Index'] if row['Date'] == \"20200617\" else \"0\", axis=1\n",
    ")\n",
    "\n",
    "State_Restrictions_df['State_Government_Response_Index_06172020'] = State_Restrictions_df.apply(\n",
    "    lambda row: row['State_Government_Response_Index'] if row['State_Government_Response_Index_06172020'] == \"0\" else row['State_Government_Response_Index_06172020'], axis=1\n",
    ")\n",
    "\n",
    "State_Restrictions_df['State_Government_Response_Index_11192020'] = State_Restrictions_df.apply(\n",
    "    lambda row: row['State_Government_Response_Index'] if row['Date'] == \"20201129\" else \"0\", axis=1\n",
    ")\n",
    "\n",
    "State_Restrictions_df['State_Government_Response_Index_11192020'] = State_Restrictions_df.apply(\n",
    "    lambda row: row['State_Government_Response_Index'] if row['State_Government_Response_Index_11192020'] == \"0\" else row['State_Government_Response_Index_11192020'], axis=1\n",
    ")\n",
    "\n",
    "State_Restrictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941a5c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ZIP_FEATURES = pd.merge(ZIP_FEATURES, State_Restrictions_df, on = \"STATE\", how = \"left\")\n",
    "\n",
    "ZIP_FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f816fbd",
   "metadata": {},
   "source": [
    "Next, I want to read in the county level presidential data and generate two variables \\\n",
    "1. For which president did the county overall vote for?\n",
    "2. What percentage of the county voted for which president?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188950dd",
   "metadata": {},
   "source": [
    "note: I manually added in DC because it was not in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66e46e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_types = {\n",
    "    'county_fips': str,\n",
    "}\n",
    "county_pres = pd.read_csv('Data/Partisanship and Health Behavior/Data/countypres_2000-2020.csv', dtype = col_types)\n",
    "county_pres = county_pres[county_pres['year'] == 2020].reset_index(drop=True)\n",
    "\n",
    "county_pres['party_fips'] = county_pres['party'].astype(str) + county_pres['county_fips'].astype(str)\n",
    "\n",
    "#there was an issue where there were multiple types of votes on each line for the same person\n",
    "total_votes_by_party = county_pres.groupby('party_fips')['candidatevotes'].sum().reset_index()\n",
    "total_votes_by_party.rename(columns={'candidatevotes': 'total_candidatevotes'}, inplace=True)\n",
    "\n",
    "county_pres = county_pres.merge(total_votes_by_party, on='party_fips', how='left')\n",
    "\n",
    "county_pres['percentage_won'] = (county_pres['total_candidatevotes'] / county_pres['totalvotes'])*100\n",
    "\n",
    "# Group by 'countyfips' and find the index of the row with the largest 'percentage_won' in each group\n",
    "county_pres_wide = county_pres.groupby('county_fips')['percentage_won'].idxmax()\n",
    "\n",
    "# Select rows from the original DataFrame corresponding to these indices\n",
    "county_pres_wide = county_pres.loc[county_pres_wide]\n",
    "\n",
    "county_pres_wide = county_pres_wide.rename(columns={\n",
    "    'candidate': 'winning_pres_candidate',\n",
    "    'party':'winning_pres_party',\n",
    "    'percentage_won': 'winning_pres_candidate_percentage'\n",
    "})\n",
    "\n",
    "#merge in the dems\n",
    "dem_county_pres = county_pres[county_pres['party'] == 'DEMOCRAT']\n",
    "\n",
    "dem_county_pres.rename(columns={'percentage_won': 'biden_percentage_won'}, inplace=True)\n",
    "\n",
    "dem_county_pres = dem_county_pres[['biden_percentage_won','county_fips']]\n",
    "\n",
    "county_pres_wide = county_pres_wide.merge(dem_county_pres, on='county_fips', how='left')\n",
    "\n",
    "#merge in the reps\n",
    "rep_county_pres = county_pres[county_pres['party'] == 'REPUBLICAN']\n",
    "\n",
    "rep_county_pres.rename(columns={'percentage_won': 'trump_percentage_won'}, inplace=True)\n",
    "\n",
    "rep_county_pres = rep_county_pres[['trump_percentage_won','county_fips']]\n",
    "\n",
    "county_pres_wide = county_pres_wide.merge(rep_county_pres, on='county_fips', how='left')\n",
    "\n",
    "#keeping only the columns I want\n",
    "county_pres_wide = county_pres_wide.drop(columns =['year','state','state_po','county_name','office','candidatevotes','totalvotes','version','mode','party_fips'])\n",
    "\n",
    "county_pres_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e01bc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "county_pres_wide = county_pres_wide.rename(columns={\n",
    "    'county_fips': 'COUNTY_FIPS'\n",
    "})\n",
    "\n",
    "ZIP_FEATURES = pd.merge(ZIP_FEATURES, county_pres_wide, on = \"COUNTY_FIPS\", how = \"left\")\n",
    "\n",
    "ZIP_FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35b538f",
   "metadata": {},
   "source": [
    "Next, for the sake of consistency, I want to get data on the percentage of the CD that was won by a democrat and Republican, respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd01f3f",
   "metadata": {},
   "source": [
    "However, I need a clean crosswalk (as this one is pulling out several duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83926e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_types = {\n",
    "    'DISTRICT': str,\n",
    "}\n",
    "\n",
    "county_CD_share = pd.read_excel('Data/Partisanship and Health Behavior/Data/federalelections2020.xlsx', \n",
    "                                sheet_name='13_US_House_Results_State', \n",
    "                                dtype=col_types)\n",
    "\n",
    "county_CD_share = county_CD_share.rename(columns={\n",
    "    'DISTRICT': 'CD_DISTRICT'\n",
    "})\n",
    "\n",
    "county_CD_share = county_CD_share[pd.notna(county_CD_share['GENERAL %'])].reset_index(drop=True)\n",
    "\n",
    "county_CD_share = pd.merge(county_CD_share, State_FIPS_Crosswalk, how='left', on=\"STATE\")\n",
    "\n",
    "county_CD_share['STATE_FIPS'] = county_CD_share['STATE_FIPS'].astype(str)\n",
    "county_CD_share['CD_DISTRICT'] = county_CD_share['CD_DISTRICT'].astype(str)\n",
    "\n",
    "county_CD_share['STATE_FIPS'] = county_CD_share['STATE_FIPS'].apply(lambda x: '0' + x if len(x) == 1 else x)\n",
    "county_CD_share['CD_DISTRICT'] = county_CD_share['CD_DISTRICT'].apply(lambda x: '0' + x if len(x) == 1 else x)\n",
    "\n",
    "county_CD_share['CD'] = county_CD_share['STATE_FIPS'] + county_CD_share['CD_DISTRICT']\n",
    "\n",
    "county_CD_share.to_csv('data/CD_COUNTY_PERCENT_WON.csv')\n",
    "\n",
    "D_county_CD_share = county_CD_share[county_CD_share['PARTY'].str.contains(\"D\")].reset_index(drop=True)\n",
    "D_county_CD_share = D_county_CD_share[['GENERAL %','CD']]\n",
    "\n",
    "D_county_CD_share = D_county_CD_share.rename(columns={\n",
    "    'GENERAL %': 'CD_PERCENT_DEMOCRAT'\n",
    "})\n",
    "\n",
    "R_county_CD_share = county_CD_share[county_CD_share['PARTY'].str.contains(\"R\")].reset_index(drop=True)\n",
    "R_county_CD_share = R_county_CD_share[['GENERAL %','CD']]\n",
    "\n",
    "R_county_CD_share = R_county_CD_share.rename(columns={\n",
    "    'GENERAL %': 'CD_PERCENT_REPUBLICAN'\n",
    "})\n",
    "\n",
    "D_county_CD_share = D_county_CD_share[D_county_CD_share['CD'].notna()]\n",
    "R_county_CD_share = R_county_CD_share[R_county_CD_share['CD'].notna()]\n",
    "\n",
    "ZIP_FEATURES = pd.merge(ZIP_FEATURES, D_county_CD_share, how = 'left', on = \"CD\")\n",
    "ZIP_FEATURES = pd.merge(ZIP_FEATURES, R_county_CD_share, how = 'left', on = \"CD\")\n",
    "\n",
    "print(ZIP_FEATURES['CD_PERCENT_REPUBLICAN'].isna().sum())\n",
    "print(ZIP_FEATURES['CD_PERCENT_REPUBLICAN'].isna().mean() * 100)\n",
    "\n",
    "#manually adjusting these rows that received 0 votes in democratic counties\n",
    "ZIP_FEATURES['CD_PERCENT_REPUBLICAN'] = ZIP_FEATURES.apply(\n",
    "    lambda row: 0 if pd.notna(row['CD_PERCENT_DEMOCRAT']) and pd.isna(row['CD_PERCENT_REPUBLICAN']) else row['CD_PERCENT_REPUBLICAN'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "#now in republican counties\n",
    "ZIP_FEATURES['CD_PERCENT_DEMOCRAT'] = ZIP_FEATURES.apply(\n",
    "    lambda row: 0 if row['CD_PERCENT_REPUBLICAN'] != 0 and pd.notna(row['CD_PERCENT_REPUBLICAN']) and pd.isna(row['CD_PERCENT_DEMOCRAT']) else row['CD_PERCENT_DEMOCRAT'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "ZIP_FEATURES['CD'] = ZIP_FEATURES.apply(lambda row: 0 if row['CD'] == \"1225\" else row['CD'],\n",
    "                                                        axis=1)\n",
    "\n",
    "ZIP_FEATURES['CD'] = ZIP_FEATURES.apply(lambda row: 100 if row['CD'] == \"1225\" else row['CD'],\n",
    "                                                        axis=1)\n",
    "\n",
    "print(ZIP_FEATURES['CD_PERCENT_REPUBLICAN'].isna().sum())\n",
    "print(ZIP_FEATURES['CD_PERCENT_REPUBLICAN'].isna().mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152462c9",
   "metadata": {},
   "source": [
    "Lastly, I want to merge in demographic data by CD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd35db75",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_types = {\n",
    "    'GEO_ID': str,\n",
    "}\n",
    "\n",
    "CD_demographics = pd.read_csv('data/ACSDP5Y2020.DP05-Data.csv', dtype=col_types, header=1)\n",
    "\n",
    "CD_demographics = CD_demographics[['Geography', 'Geographic Area Name', 'Estimate!!SEX AND AGE!!Total population', \n",
    "                                   'Estimate!!SEX AND AGE!!Total population!!Female', 'Estimate!!SEX AND AGE!!Total population!!Sex ratio (males per 100 females)',\n",
    "                                  'Estimate!!SEX AND AGE!!Total population!!Under 5 years', 'Estimate!!SEX AND AGE!!Total population!!65 to 74 years',\n",
    "                                  'Estimate!!SEX AND AGE!!Total population!!75 to 84 years','Estimate!!SEX AND AGE!!Total population!!85 years and over',\n",
    "                                  'Estimate!!SEX AND AGE!!Total population!!Median age (years)','Estimate!!RACE!!Total population',\n",
    "                                  'Estimate!!RACE!!Total population!!One race','Estimate!!RACE!!Total population!!Two or more races',\n",
    "                                  'Estimate!!RACE!!Total population!!One race!!White','Estimate!!RACE!!Total population!!One race!!Black or African American',\n",
    "                                  'Estimate!!RACE!!Total population!!One race!!American Indian and Alaska Native','Estimate!!RACE!!Total population!!One race!!Asian',\n",
    "                                  'Estimate!!RACE!!Total population!!One race!!Asian!!Asian Indian','Margin of Error!!Race alone or in combination with one or more other races!!Total population!!White',\n",
    "                                  'Estimate!!Race alone or in combination with one or more other races!!Total population!!Black or African American',\n",
    "                                  'Estimate!!Race alone or in combination with one or more other races!!Total population!!American Indian and Alaska Native',\n",
    "                                  'Estimate!!Race alone or in combination with one or more other races!!Total population!!Asian',\n",
    "                                  'Estimate!!HISPANIC OR LATINO AND RACE!!Total population',\n",
    "                                  'Estimate!!HISPANIC OR LATINO AND RACE!!Total population!!Hispanic or Latino (of any race)',\n",
    "                                  'Estimate!!HISPANIC OR LATINO AND RACE!!Total population!!Not Hispanic or Latino',\n",
    "                                  'Percent!!SEX AND AGE!!Total population!!65 years and over',\n",
    "                                  'Percent!!RACE!!Total population!!One race','Percent!!RACE!!Total population!!Two or more races',\n",
    "                                  'Percent!!RACE!!Total population!!One race!!White','Percent!!RACE!!Total population!!One race!!Black or African American',\n",
    "                                  'Percent!!RACE!!Total population!!One race!!American Indian and Alaska Native','Percent!!RACE!!Total population!!One race!!Asian',\n",
    "                                  'Percent!!RACE!!Total population!!One race!!Asian!!Asian Indian','Percent!!Race alone or in combination with one or more other races!!Total population!!White',\n",
    "                                  'Percent!!Race alone or in combination with one or more other races!!Total population!!Black or African American',\n",
    "                                  'Percent!!Race alone or in combination with one or more other races!!Total population!!American Indian and Alaska Native',\n",
    "                                  'Percent!!Race alone or in combination with one or more other races!!Total population!!Asian',\n",
    "                                  'Percent!!HISPANIC OR LATINO AND RACE!!Total population!!Hispanic or Latino (of any race)',\n",
    "                                  'Percent!!HISPANIC OR LATINO AND RACE!!Total population!!Not Hispanic or Latino']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e34bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ZIP_FEATURES.to_csv('data/ZIP_Features.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acec07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ZIP_FEATURES.to_csv('data/Partisanship and Health Behavior/Data/ZIP_Features.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc51fa3",
   "metadata": {},
   "source": [
    "Why is resp_educ and education different?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddd1d31",
   "metadata": {},
   "source": [
    "Now I'll merge to the BICS file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bee07c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_types = {\n",
    "    'resp_zip': str,\n",
    "    'political_party': str\n",
    "}\n",
    "\n",
    "df_w1 = pd.read_csv('/Users/chrissoria/Documents/Research/BICS/data/national_wave1_unweighted.csv', dtype = col_types)\n",
    "df_w2 = pd.read_csv('/Users/chrissoria/Documents/Research/BICS/data/national_wave2_unweighted.csv', dtype = col_types)\n",
    "df_w3 = pd.read_csv('/Users/chrissoria/Documents/Research/BICS/data/national_wave3_unweighted.csv', dtype = col_types)\n",
    "df_w4 = pd.read_csv('/Users/chrissoria/Documents/Research/BICS/data/national_wave4_unweighted.csv', dtype = col_types)\n",
    "df_w5 = pd.read_csv('/Users/chrissoria/Documents/Research/BICS/data/national_wave5_unweighted.csv', dtype = col_types)\n",
    "df_w6 = pd.read_csv('/Users/chrissoria/Documents/Research/BICS/data/national_wave6_unweighted.csv', dtype = col_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbacf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"resp_employ\" in df_w2.columns:\n",
    "    df_w2[\"resp_employ\"] = df_w2[\"resp_employ\"].astype(str)\n",
    "\n",
    "if \"resp_employ\" in df_w3.columns:\n",
    "    df_w3[\"resp_employ\"] = df_w3[\"resp_employ\"].astype(str)    \n",
    "    \n",
    "if \"resp_employ\" in df_w4.columns:\n",
    "    df_w4[\"resp_employ\"] = df_w4[\"resp_employ\"].astype(str)\n",
    "    \n",
    "if \"resp_employ\" in df_w5.columns:\n",
    "    df_w5[\"resp_employ\"] = df_w5[\"resp_employ\"].astype(str)\n",
    "\n",
    "if \"resp_employ\" in df_w6.columns:\n",
    "    df_w6[\"resp_employ\"] = df_w6[\"resp_employ\"].astype(str)\n",
    "    \n",
    "df_w2['resp_occupation'] = df_w2['resp_occupation'].astype(str)\n",
    "df_w4['resp_occupation'] = df_w4['resp_occupation'].astype(str)\n",
    "\n",
    "df_combined = pd.concat([df_w2, df_w3, df_w4, df_w5, df_w6], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e741abd3",
   "metadata": {},
   "source": [
    "Below I'm converting the waves into date ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebb7a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['data_collected_dates'] = df_combined.apply(lambda row: \"June 18-24, '20\" if row['wave'] == 2\n",
    "                                                       else \"September 12-20, '20'\" if row['wave'] == 3\n",
    "                                                       else \"December 1-7, '20'\" if row['wave'] == 4\n",
    "                                                       else \"February 9-14, '21'\" if row['wave'] == 5\n",
    "                                                       else \"May 14-25, '21'\" if row['wave'] == 6\n",
    "                                                        else np.nan, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c39b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_combined['data_collected_dates'].value_counts())\n",
    "print(df_combined['wave'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b181c171",
   "metadata": {},
   "source": [
    "We're missing a \"conservative\" but we have two moderates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe8aeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "political_view_mapping = {\n",
    "    'Extremely conservative': 1,\n",
    "    'Slightly conservative': 2,\n",
    "    'Moderate': 3,\n",
    "    'Middle of the road': 3,\n",
    "    'Slightly liberal': 4,\n",
    "    'Liberal': 5,\n",
    "    'Extremely liberal': 6\n",
    "}\n",
    "\n",
    "# Creating a new variable 'political_view_numeric' by mapping the 'political_view' column using the defined mapping\n",
    "df_combined['political_view_numeric'] = df_combined['political_view'].replace(political_view_mapping)\n",
    "\n",
    "df_combined['political_view'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a516ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#education variable\n",
    "def categorize_education(row):\n",
    "    if row['resp_educ'] == \"Less than high school degree\":\n",
    "        return \"Less than high school\"\n",
    "    elif row['resp_educ'] in [\"High school graduate (high school diploma or equivalent including GED)\", \"Some college but no degree\", \"Associate degree in college (2-year)\"]:\n",
    "        return \"High school graduate\"\n",
    "    elif row['resp_educ'] in [\"Bachelor's degree in college (4-year)\", \"Master's degree\", \"Doctoral degree\", \"Professional degree (JD, MD)\"]:\n",
    "        return \"College graduate and above\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "df_combined['educ_group'] = df_combined.apply(categorize_education, axis=1)\n",
    "\n",
    "df_combined['educ_group'].value_counts(dropna=False)\n",
    "\n",
    "race_columns = [col for col in df_combined.columns if col.startswith('resp_race_')]\n",
    "df_combined[race_columns] = df_combined[race_columns].fillna(0)\n",
    "\n",
    "#race variable\n",
    "def categorize_race(row):\n",
    "    if row['resp_race_1'] == \"White\":\n",
    "        return \"White\"\n",
    "    elif row['resp_race_2'] == \"Black or African American\":\n",
    "        return \"Black\"\n",
    "    elif row['resp_race_4'] == \"Asian\":\n",
    "        return \"Asian\"\n",
    "    else:\n",
    "        return \"Other / Mixed\"\n",
    "\n",
    "df_combined['r_race'] = df_combined.apply(categorize_race, axis=1)\n",
    "\n",
    "print(df_combined['r_race'].value_counts(dropna=False))\n",
    "\n",
    "#employment variable\n",
    "employment_columns = [col for col in df_combined.columns if col.startswith('resp_employ_')]\n",
    "df_combined[employment_columns] = df_combined[employment_columns].fillna(0)\n",
    "\n",
    "# Create the 'r_working' var based whether reported\n",
    "df_combined['r_working'] = np.where(df_combined['industry'] == \"I don't work\", \"Not Working\", \"Working\")\n",
    "\n",
    "print(df_combined['r_working'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf72612",
   "metadata": {},
   "source": [
    "dependent variable for concern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce3edea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['binary_concern'] = df_combined['covid19_concern'].apply(\n",
    "    lambda x: 1 if x in [\"Somewhat concerned\", \"Very concerned\"] else (0 if pd.notna(x) else None)\n",
    ")\n",
    "\n",
    "df_combined['binary_concern_strong'] = df_combined['covid19_concern'].apply(\n",
    "    lambda x: 1 if x == \"Very concerned\" else (0 if pd.notna(x) else None)\n",
    ")\n",
    "\n",
    "df_combined['contact_reduction'] = df_combined['covid19_f2fchange'].apply(\n",
    "    lambda x: 1 if x == \"I have greatly reduced face-to-face interaction with others\" else (0 if pd.notna(x) else None)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235a5c4e",
   "metadata": {},
   "source": [
    "reading in the alter files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b497ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w2_nonhhalters = pd.read_csv(\"/Users/chrissoria/documents/research/BICs/data/national_alters_nonhh_wave2_unweighted.csv\")\n",
    "df_w3_nonhhalters = pd.read_csv(\"/Users/chrissoria/documents/research/BICs/data/national_alters_nonhh_wave3_unweighted.csv\")\n",
    "df_w4_nonhhalters = pd.read_csv(\"/Users/chrissoria/documents/research/BICs/data/national_alters_nonhh_wave4_unweighted.csv\")\n",
    "df_w5_nonhhalters = pd.read_csv(\"/Users/chrissoria/documents/research/BICs/data/national_alters_nonhh_wave5_unweighted.csv\")\n",
    "df_w6_nonhhalters = pd.read_csv(\"/Users/chrissoria/documents/research/BICs/data/national_alters_nonhh_wave6_unweighted.csv\")\n",
    "\n",
    "df_alters_combined = pd.concat([df_w2_nonhhalters, df_w3_nonhhalters, df_w4_nonhhalters, df_w5_nonhhalters, df_w6_nonhhalters], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0734c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary indicators for mask, gloves, and other protective equipment usage\n",
    "df_alters_combined['Mask_Used'] = (\n",
    "    ((df_alters_combined['protection_1'] == \"Wear a face mask\") |\n",
    "    (df_alters_combined['protection_2'] == \"Wear a face mask\") |\n",
    "    (df_alters_combined['protection_3'] == \"Wear a face mask\") |\n",
    "    (df_alters_combined['protection_4'] == \"Wear a face mask\")).astype(int)\n",
    ")\n",
    "\n",
    "df_alters_combined['Gloves_Used'] = (\n",
    "    ((df_alters_combined['protection_1'] == \"Wear gloves\") |\n",
    "    (df_alters_combined['protection_2'] == \"Wear gloves\") |\n",
    "    (df_alters_combined['protection_3'] == \"Wear gloves\") |\n",
    "    (df_alters_combined['protection_4'] == \"Wear gloves\")).astype(int)\n",
    ")\n",
    "\n",
    "df_alters_combined['Other_Protective_Equipment_Used'] = (\n",
    "    ((df_alters_combined['protection_1'] == \"Wear other protective equipment\") |\n",
    "    (df_alters_combined['protection_2'] == \"Wear other protective equipment\") |\n",
    "    (df_alters_combined['protection_3'] == \"Wear other protective equipment\") |\n",
    "    (df_alters_combined['protection_4'] == \"Wear other protective equipment\")).astype(int)\n",
    ")\n",
    "\n",
    "# Aggregate these indicators at the 'rid' level\n",
    "df_aggregated = df_alters_combined.groupby('rid').agg(\n",
    "    Total_Masks_Used=('Mask_Used', 'sum'),\n",
    "    Total_Gloves_Used=('Gloves_Used', 'sum'),\n",
    "    Total_Other_Protective_Equipment_Used=('Other_Protective_Equipment_Used', 'sum'),\n",
    "    Contacts=('rid', 'size')\n",
    ").reset_index()\n",
    "\n",
    "# Normalize the counts by the number of contacts\n",
    "df_aggregated['Norm_Masks_Used'] = df_aggregated['Total_Masks_Used'] / df_aggregated['Contacts']\n",
    "df_aggregated['Norm_Gloves_Used'] = df_aggregated['Total_Gloves_Used'] / df_aggregated['Contacts']\n",
    "df_aggregated['Norm_Other_Protective_Equipment_Used'] = df_aggregated['Total_Other_Protective_Equipment_Used'] / df_aggregated['Contacts']\n",
    "\n",
    "# Calculate non-weighted and weighted safety indices\n",
    "df_aggregated['Non_Weighted_Safety_Index'] = (\n",
    "    df_aggregated['Norm_Masks_Used'] + \n",
    "    df_aggregated['Norm_Gloves_Used'] + \n",
    "    df_aggregated['Norm_Other_Protective_Equipment_Used']\n",
    ") / 3\n",
    "\n",
    "df_aggregated['Weighted_Safety_Index'] = (\n",
    "    df_aggregated['Norm_Masks_Used'] + \n",
    "    df_aggregated['Norm_Gloves_Used'] + \n",
    "    df_aggregated['Norm_Other_Protective_Equipment_Used']\n",
    ") / (3 * df_aggregated['Contacts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4610d670",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_contacts = pd.merge(df_combined, df_aggregated, on = \"rid\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e66c35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_contacts['wave'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615239c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_contacts['political_party'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0e80b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_contacts.to_csv('data/BICS_ego_alters_merged.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab44200",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_types = {\n",
    "    'ZIP': str,\n",
    "    'CD':str,\n",
    "    'COUNTY_FIPS':str,\n",
    "    'STATE_FIPS':str,\n",
    "    'CONGRESSPERSON_PARTY': str\n",
    "}\n",
    "\n",
    "ZIP_FEATURES = pd.read_csv('/Users/chrissoria/Documents/Research/BICS_Political_Polarization/data/ZIP_Features.csv',\n",
    "                          dtype=col_types)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9b9daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_types = {\n",
    "    'resp_zip': str,\n",
    "    'political_party': str\n",
    "}\n",
    "\n",
    "all_waves = df_combined_contacts\n",
    "\n",
    "all_waves = all_waves.rename(columns={\n",
    "    'resp_zip': 'ZIP'\n",
    "})\n",
    "\n",
    "all_waves['ZIP'] = all_waves['ZIP'].str.strip()\n",
    "\n",
    "columns_to_keep = ['ResponseId','StartDate','resp_yob','resp_sex','resp_hispanic','r_race','resp_nativity','ZIP',\n",
    "                  'resp_hhsize','r_working','resp_occupation','lefthome_num','num_cc_nonhh',\n",
    "                  'lefthome_where_1','lefthome_where_2','lefthome_where_3','lefthome_where_4','lefthome_where_10',\n",
    "                  'lefthome_where_8','lefthome_where_9','lefthome_where_5','lefthome_where_11','lefthome_where_6',\n",
    "                  'lefthome_where_7','inet_freq','socmedia_use','covid19_familiar','covid19_concern',\n",
    "                  'covid19_f2fchange','covid19_reduceOK','policy_sip','age','hhi','political_party','political_view',\n",
    "                  'industry','health_insurance','interview_date','wave','agecat','city','covid19_vax','covid19_whynot_vax',\n",
    "                  'Non_Weighted_Safety_Index','Weighted_Safety_Index','Norm_Masks_Used','educ_group','contact_reduction',\n",
    "                  'binary_concern','binary_concern_strong','resp_educ','resp_sex','Contacts','Non_Weighted_Safety_Index',\n",
    "                  'Weighted_Safety_Index','data_collected_dates']\n",
    "all_waves = all_waves[columns_to_keep]\n",
    "\n",
    "all_waves['political_party'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eefe16d",
   "metadata": {},
   "source": [
    "How many people have a ZIP code? ALL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad242117",
   "metadata": {},
   "source": [
    "what percentage of these are 5 digit zip codes? A lot of these are four digit zip codes. There are so few of them it's not worth trying to figure out where they are (4 digits is enough to tell me something about their localility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6773d3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BICS_ZIP_FEATURES = pd.merge(all_waves, ZIP_FEATURES, on = \"ZIP\", how = \"left\")\n",
    "BICS_ZIP_FEATURES = BICS_ZIP_FEATURES.drop_duplicates(subset='ResponseId', keep='first')\n",
    "BICS_ZIP_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be196fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(BICS_ZIP_FEATURES['ZIP'].isna().sum())\n",
    "print(BICS_ZIP_FEATURES['ZIP'].isna().mean() *100)\n",
    "print((BICS_ZIP_FEATURES['ZIP'].apply(lambda x: len(str(x)) == 5).mean()) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28190e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BICS_ZIP_FEATURES['junk_zip'] = BICS_ZIP_FEATURES['ZIP'].apply(lambda x: 1 if len(str(x)) == 5 else 0)\n",
    "BICS_junk_zips = BICS_ZIP_FEATURES[BICS_ZIP_FEATURES['junk_zip'] == 0]\n",
    "BICS_junk_zips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c36d05",
   "metadata": {},
   "source": [
    "How many zip codes are being matched? \\\n",
    "currently I'm getting, 33 percent large percent missing. \\\n",
    "Fixed the issue by reading in ZIPS as string at the top now only .8788 don't match "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dc7f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(BICS_ZIP_FEATURES['USPS_STATE'].isna().sum())\n",
    "print(BICS_ZIP_FEATURES['USPS_STATE'].isna().mean() *100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90792bc",
   "metadata": {},
   "source": [
    "what about school closures? \\\n",
    "About 9 percent of people have a missing school matched to their ZIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5277be4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(BICS_ZIP_FEATURES['earlyfall2020_school_closures'].isna().sum())\n",
    "print(BICS_ZIP_FEATURES['earlyfall2020_school_closures'].isna().mean() *100)\n",
    "\n",
    "print(BICS_ZIP_FEATURES['fall2020_school_closures'].isna().sum())\n",
    "print(BICS_ZIP_FEATURES['fall2020_school_closures'].isna().mean() *100)\n",
    "\n",
    "print(BICS_ZIP_FEATURES['spring2021_school_closures'].isna().sum())\n",
    "print(BICS_ZIP_FEATURES['spring2021_school_closures'].isna().mean() *100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb680fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "BICS_ZIP_FEATURES['political_party_to_CD'] = BICS_ZIP_FEATURES.apply(\n",
    "    lambda row: str(row['political_party']) + \" in \" + str(row['CONGRESSPERSON_PARTY']) + \" led CD\", axis=1\n",
    ")\n",
    "\n",
    "# Print the updated DataFrame to see if it matches\n",
    "print(BICS_ZIP_FEATURES[['political_party', 'CONGRESSPERSON_PARTY', 'political_party_to_CD']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56a7ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "BICS_ZIP_FEATURES['political_party'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4354141d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BICS_ZIP_FEATURES['CONGRESSPERSON_PARTY'] = BICS_ZIP_FEATURES['CONGRESSPERSON_PARTY'].replace(\"Democratic\", \"Democrat\")\n",
    "BICS_ZIP_FEATURES['In_Opposing_Party_CD'] = ((BICS_ZIP_FEATURES['political_party'] != BICS_ZIP_FEATURES['CONGRESSPERSON_PARTY']) & ~pd.isna(BICS_ZIP_FEATURES['CONGRESSPERSON_PARTY'])).astype(int)\n",
    "BICS_ZIP_FEATURES['Independent'] = (BICS_ZIP_FEATURES['political_party'] == \"Independent\").astype(int)\n",
    "BICS_ZIP_FEATURES['Vaccinated'] = BICS_ZIP_FEATURES['covid19_vax'].apply(\n",
    "    lambda x: 1 if x == \"Yes, I have received at least one dose of a vaccine\" else\n",
    "              (0 if x == \"No, I have not\" else np.nan)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07fd8c7",
   "metadata": {},
   "source": [
    "Does it make sense to drop Independents? \\\n",
    "They're kind of in their own cateogory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835921a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(BICS_ZIP_FEATURES['In_Opposing_Party_CD'].value_counts())\n",
    "print(BICS_ZIP_FEATURES['political_party'].value_counts())\n",
    "print(BICS_ZIP_FEATURES['CONGRESSPERSON_PARTY'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22112fc7",
   "metadata": {},
   "source": [
    "Below I convert the raw numbers to categories for Trump and Biden share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa630a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BICS_ZIP_FEATURES['Categorical_Trump_County_Share'] = BICS_ZIP_FEATURES['trump_percentage_won'].apply(lambda x:\n",
    "    \"Less Than a Third\" if x < 33.1 else\n",
    "    \"Less than Two Thirds Greater Than One Third\" if x < 66.1 else\n",
    "    \"Greater than or Equal to Two thirds\" if x >= 66.1 else pd.NA\n",
    ")\n",
    "\n",
    "BICS_ZIP_FEATURES['Categorical_Biden_County_Share'] = BICS_ZIP_FEATURES['biden_percentage_won'].apply(lambda x:\n",
    "    \"Less Than a Third\" if x < 33.1 else\n",
    "    \"Less than Two Thirds Greater Than One Third\" if x < 66.1 else\n",
    "    \"Greater than or Equal to Two thirds\" if x >= 66.1 else pd.NA\n",
    ")\n",
    "\n",
    "BICS_ZIP_FEATURES['Percentage_Trump_Greater_Than_Two_Thirds'] = BICS_ZIP_FEATURES['trump_percentage_won'].apply(lambda x:\n",
    "    1 if x >= 66.1 else\n",
    "    0 if x < 66.1 else pd.NA\n",
    ")\n",
    "\n",
    "BICS_ZIP_FEATURES['Percentage_Trump_Less_Than_Two_Thirds'] = BICS_ZIP_FEATURES['trump_percentage_won'].apply(lambda x:\n",
    "    1 if x < 66.1 else\n",
    "    0 if x <= 66.1 else pd.NA\n",
    ")\n",
    "\n",
    "BICS_ZIP_FEATURES['Percentage_Biden_Greater_Than_Two_Thirds'] = BICS_ZIP_FEATURES['biden_percentage_won'].apply(lambda x:\n",
    "    1 if x >= 66.1 else\n",
    "    0 if x < 66.1 else pd.NA\n",
    ")\n",
    "\n",
    "BICS_ZIP_FEATURES['Percentage_Biden_Less_Than_Two_Thirds'] = BICS_ZIP_FEATURES['biden_percentage_won'].apply(lambda x:\n",
    "    1 if x < 66.1 else\n",
    "    0 if x <= 66.1 else pd.NA\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c585d28",
   "metadata": {},
   "source": [
    "Next, I use the same logic to create the CD categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a840243",
   "metadata": {},
   "outputs": [],
   "source": [
    "BICS_ZIP_FEATURES['Categorical_Repub_CD_County_Share'] = BICS_ZIP_FEATURES['CD_PERCENT_REPUBLICAN'].apply(lambda x:\n",
    "    \"Less Than a Quarter\" if x < .25 else\n",
    "    \"Two Quarters\" if x < .50 and x >.25 else\n",
    "    \"Three Quarters\" if x < .75 and x > .50 else\n",
    "    \"Greater than or Equal to Three Quarters\" if x >= .75 else pd.NA\n",
    ")\n",
    "\n",
    "BICS_ZIP_FEATURES['Categorical_Dem_CD_County_Share'] = BICS_ZIP_FEATURES['CD_PERCENT_DEMOCRAT'].apply(lambda x:\n",
    "    \"Less Than a Quarter\" if x < .25 else\n",
    "    \"Two Quarters\" if x < .50 else\n",
    "    \"Three Quarters\" if x < .75 else\n",
    "    \"Greater than or Equal to Three Quarters\" if x >= .75 else pd.NA\n",
    ")\n",
    "\n",
    "BICS_ZIP_FEATURES['Categorical_Repub_CD_County_Share'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaa8f36",
   "metadata": {},
   "source": [
    "Next, let's add a variable that treats urban and rural as a binary. \\\n",
    "1 = Metro - Counties in metro areas of 1 million population or more \\\n",
    "2 = Metro - Counties in metro areas of 250,000 to 1 million population \\         \n",
    "3 = Metro - Counties in metro areas of fewer than 250,000 population \\\n",
    "4 = Nonmetro - Urban population of 20,000 or more, adjacent to a metro area \\\n",
    "5 = Nonmetro - Urban population of 20,000 or more, not adjacent to a metro area \\\n",
    "6 = Nonmetro - Urban population of 2,500 to 19,999, adjacent to a metro area \\\n",
    "7 = Nonmetro - Urban population of 2,500 to 19,999, not adjacent to a metro area \\\n",
    "8 = Nonmetro - Completely rural or less than 2,500 urban population, adjacent to a metro area \\\n",
    "9 = Nonmetro - Completely rural or less than 2,500 urban population, not adjacent to a metro area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1588897a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BICS_ZIP_FEATURES['COUNT_RUCC_CAT'] = BICS_ZIP_FEATURES['COUNTY_RUCC_2013'].apply(\n",
    "    lambda x: \"Urban Metro\" if x in [1, 2] else\n",
    "              \"Urban Nonmetro\" if x in list(range(3, 8)) else \n",
    "              \"Rural\" if x in [8, 9] else np.nan\n",
    ")\n",
    "\n",
    "BICS_ZIP_FEATURES['COUNT_RUCC_BINARY'] = BICS_ZIP_FEATURES['COUNTY_RUCC_2013'].apply(\n",
    "    lambda x: \"Urban\" if x in list(range(1, 8)) else  \n",
    "              \"Rural\" if x in [8, 9] else np.nan\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9502c0",
   "metadata": {},
   "source": [
    "Dopping all non-national values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1856f9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "BICS_ZIP_FEATURES['city'].value_counts()\n",
    "\n",
    "BICS_ZIP_FEATURES = BICS_ZIP_FEATURES[BICS_ZIP_FEATURES['city'] == \"National\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a20a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "BICS_ZIP_FEATURES.to_csv('data/BICS_ZIP_Features.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbde180",
   "metadata": {},
   "outputs": [],
   "source": [
    "BICS_ZIP_FEATURES.to_csv('data/Partisanship and Health Behavior/Data/BICS_ZIP_Features.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
