{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "935059a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d27e7345",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/chrissoria/Documents/Research/BICS_Political_Polarization/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153a6a01",
   "metadata": {},
   "source": [
    "For this preliminary analysis, I will only use wave 2,4,6. \\\n",
    "Each wave's data was collected on 2020-06-17 - 2020-06-23, 2020-11-29 - 2020-12-16, 2021-05-12 - 2021-05-25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb94ed27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/89/6bdxzk2j30v5n3wstywbcpg80000gn/T/ipykernel_64930/808921033.py:6: DtypeWarning: Columns (84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_w6 = pd.read_csv('/Users/chrissoria/Documents/Research/BICS/data/national_wave6_unweighted.csv')\n"
     ]
    }
   ],
   "source": [
    "df_w1 = pd.read_csv('/Users/chrissoria/Documents/Research/BICS/data/national_wave1_unweighted.csv')\n",
    "df_w2 = pd.read_csv('/Users/chrissoria/Documents/Research/BICS/data/national_wave2_unweighted.csv')\n",
    "df_w3 = pd.read_csv('/Users/chrissoria/Documents/Research/BICS/data/national_wave3_unweighted.csv')\n",
    "df_w4 = pd.read_csv('/Users/chrissoria/Documents/Research/BICS/data/national_wave4_unweighted.csv')\n",
    "df_w5 = pd.read_csv('/Users/chrissoria/Documents/Research/BICS/data/national_wave5_unweighted.csv')\n",
    "df_w6 = pd.read_csv('/Users/chrissoria/Documents/Research/BICS/data/national_wave6_unweighted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e280963c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"resp_employ\" in df_w2.columns:\n",
    "    df_w2[\"resp_employ\"] = df_w2[\"resp_employ\"].astype(str)\n",
    "\n",
    "if \"resp_employ\" in df_w3.columns:\n",
    "    df_w3[\"resp_employ\"] = df_w3[\"resp_employ\"].astype(str)    \n",
    "    \n",
    "if \"resp_employ\" in df_w4.columns:\n",
    "    df_w4[\"resp_employ\"] = df_w4[\"resp_employ\"].astype(str)\n",
    "    \n",
    "if \"resp_employ\" in df_w5.columns:\n",
    "    df_w5[\"resp_employ\"] = df_w5[\"resp_employ\"].astype(str)\n",
    "\n",
    "if \"resp_employ\" in df_w6.columns:\n",
    "    df_w6[\"resp_employ\"] = df_w6[\"resp_employ\"].astype(str)\n",
    "    \n",
    "df_w2['resp_occupation'] = df_w2['resp_occupation'].astype(str)\n",
    "df_w4['resp_occupation'] = df_w4['resp_occupation'].astype(str)\n",
    "\n",
    "df_combined = pd.concat([df_w2, df_w3, df_w4, df_w5, df_w6], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5171f5e0",
   "metadata": {},
   "source": [
    "Below I'm converting the waves into date ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc2b887e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['StartDate', 'EndDate', 'Status', 'Progress', 'Duration (in seconds)',\n",
      "       'Finished', 'RecordedDate', 'ResponseId', 'DistributionChannel',\n",
      "       'UserLanguage',\n",
      "       ...\n",
      "       'orig_education', 'w_educ', 'w_urbanrural', 'w_urbanrural2',\n",
      "       'estimated_county_fips', 'estimated_county', 'estimated_state',\n",
      "       'resp_hhsize_text', 'resp_hhsize_raw', 'resp_hhsize_topcode_val'],\n",
      "      dtype='object', length=165)\n"
     ]
    }
   ],
   "source": [
    "print(df_w2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4b9b9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interview_date\n",
      "2021-05-22    438\n",
      "2021-05-23    432\n",
      "2021-05-15    426\n",
      "2021-05-16    426\n",
      "2021-05-18    420\n",
      "2021-05-19    418\n",
      "2021-05-25    417\n",
      "2021-05-17    415\n",
      "2021-05-21    415\n",
      "2021-05-24    407\n",
      "2021-05-14    399\n",
      "2021-05-13    396\n",
      "2021-05-20    392\n",
      "2021-05-26     17\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_w6['interview_date'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e754ccef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/89/6bdxzk2j30v5n3wstywbcpg80000gn/T/ipykernel_64930/1458976774.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_combined['data_collected_dates'] = df_combined.apply(lambda row: \"June 18-24, '20\" if row['wave'] == 2\n"
     ]
    }
   ],
   "source": [
    "df_combined['data_collected_dates'] = df_combined.apply(lambda row: \"June 18-24, '20\" if row['wave'] == 2\n",
    "                                                       else \"September 12-20, '20'\" if row['wave'] == 3\n",
    "                                                       else \"December 1-7, '20'\" if row['wave'] == 4\n",
    "                                                       else \"February 9-14, '21'\" if row['wave'] == 5\n",
    "                                                       else \"May 14-25, '21'\" if row['wave'] == 6\n",
    "                                                        else np.nan, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "786cc119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_collected_dates\n",
      "May 14-25, '21'          5418\n",
      "September 12-20, '20'    3248\n",
      "December 1-7, '20'       2993\n",
      "February 9-14, '21'      2976\n",
      "June 18-24, '20          2432\n",
      "Name: count, dtype: int64\n",
      "wave\n",
      "6    5418\n",
      "3    3248\n",
      "4    2993\n",
      "5    2976\n",
      "2    2432\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_combined['data_collected_dates'].value_counts())\n",
    "print(df_combined['wave'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5caff25",
   "metadata": {},
   "source": [
    "We're missing a \"conservative\" but we have two moderates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2fe07eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/89/6bdxzk2j30v5n3wstywbcpg80000gn/T/ipykernel_64930/2967877890.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_combined['political_view_numeric'] = df_combined['political_view'].replace(political_view_mapping)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "political_view\n",
       "Moderate                  4542\n",
       "Liberal                   2695\n",
       "Slightly conservative     2277\n",
       "Extremely liberal         2262\n",
       "Extremely conservative    2021\n",
       "Middle of the road        1779\n",
       "Slightly liberal          1491\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "political_view_mapping = {\n",
    "    'Extremely conservative': 1,\n",
    "    'Slightly conservative': 2,\n",
    "    'Moderate': 3,\n",
    "    'Middle of the road': 3,\n",
    "    'Slightly liberal': 4,\n",
    "    'Liberal': 5,\n",
    "    'Extremely liberal': 6\n",
    "}\n",
    "\n",
    "# Creating a new variable 'political_view_numeric' by mapping the 'political_view' column using the defined mapping\n",
    "df_combined['political_view_numeric'] = df_combined['political_view'].replace(political_view_mapping)\n",
    "\n",
    "df_combined['political_view'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6255062a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/89/6bdxzk2j30v5n3wstywbcpg80000gn/T/ipykernel_64930/3210909615.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_combined['educ_group'] = df_combined.apply(categorize_education, axis=1)\n",
      "/var/folders/89/6bdxzk2j30v5n3wstywbcpg80000gn/T/ipykernel_64930/3210909615.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_combined['r_race'] = df_combined.apply(categorize_race, axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r_race\n",
      "White            13226\n",
      "Black             1882\n",
      "Asian             1180\n",
      "Other / Mixed      779\n",
      "Name: count, dtype: int64\n",
      "r_working\n",
      "Working        11372\n",
      "Not Working     5695\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/89/6bdxzk2j30v5n3wstywbcpg80000gn/T/ipykernel_64930/3210909615.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_combined['r_working'] = np.where(df_combined['industry'] == \"I don't work\", \"Not Working\", \"Working\")\n"
     ]
    }
   ],
   "source": [
    "#education variable\n",
    "def categorize_education(row):\n",
    "    if row['resp_educ'] == \"Less than high school degree\":\n",
    "        return \"Less than high school\"\n",
    "    elif row['resp_educ'] in [\"High school graduate (high school diploma or equivalent including GED)\", \"Some college but no degree\", \"Associate degree in college (2-year)\"]:\n",
    "        return \"High school graduate\"\n",
    "    elif row['resp_educ'] in [\"Bachelor's degree in college (4-year)\", \"Master's degree\", \"Doctoral degree\", \"Professional degree (JD, MD)\"]:\n",
    "        return \"College graduate and above\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "df_combined['educ_group'] = df_combined.apply(categorize_education, axis=1)\n",
    "\n",
    "df_combined['educ_group'].value_counts(dropna=False)\n",
    "\n",
    "race_columns = [col for col in df_combined.columns if col.startswith('resp_race_')]\n",
    "df_combined[race_columns] = df_combined[race_columns].fillna(0)\n",
    "\n",
    "#race variable\n",
    "def categorize_race(row):\n",
    "    if row['resp_race_1'] == \"White\":\n",
    "        return \"White\"\n",
    "    elif row['resp_race_2'] == \"Black or African American\":\n",
    "        return \"Black\"\n",
    "    elif row['resp_race_4'] == \"Asian\":\n",
    "        return \"Asian\"\n",
    "    else:\n",
    "        return \"Other / Mixed\"\n",
    "\n",
    "df_combined['r_race'] = df_combined.apply(categorize_race, axis=1)\n",
    "\n",
    "print(df_combined['r_race'].value_counts(dropna=False))\n",
    "\n",
    "#employment variable\n",
    "employment_columns = [col for col in df_combined.columns if col.startswith('resp_employ_')]\n",
    "df_combined[employment_columns] = df_combined[employment_columns].fillna(0)\n",
    "\n",
    "# Create the 'r_working' var based whether reported\n",
    "df_combined['r_working'] = np.where(df_combined['industry'] == \"I don't work\", \"Not Working\", \"Working\")\n",
    "\n",
    "print(df_combined['r_working'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e81b74c",
   "metadata": {},
   "source": [
    "dependent variable for concern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cb25eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/89/6bdxzk2j30v5n3wstywbcpg80000gn/T/ipykernel_64930/3902376750.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_combined['binary_concern'] = df_combined['covid19_concern'].apply(\n",
      "/var/folders/89/6bdxzk2j30v5n3wstywbcpg80000gn/T/ipykernel_64930/3902376750.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_combined['binary_concern_strong'] = df_combined['covid19_concern'].apply(\n",
      "/var/folders/89/6bdxzk2j30v5n3wstywbcpg80000gn/T/ipykernel_64930/3902376750.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_combined['contact_reduction'] = df_combined['covid19_f2fchange'].apply(\n"
     ]
    }
   ],
   "source": [
    "df_combined['binary_concern'] = df_combined['covid19_concern'].apply(\n",
    "    lambda x: 1 if x in [\"Somewhat concerned\", \"Very concerned\"] else (0 if pd.notna(x) else None)\n",
    ")\n",
    "\n",
    "df_combined['binary_concern_strong'] = df_combined['covid19_concern'].apply(\n",
    "    lambda x: 1 if x == \"Very concerned\" else (0 if pd.notna(x) else None)\n",
    ")\n",
    "\n",
    "df_combined['contact_reduction'] = df_combined['covid19_f2fchange'].apply(\n",
    "    lambda x: 1 if x == \"I have greatly reduced face-to-face interaction with others\" else (0 if pd.notna(x) else None)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7717bfb",
   "metadata": {},
   "source": [
    "reading in the alter file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d96c493c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w2_nonhhalters = pd.read_csv(\"/Users/chrissoria/documents/research/BICs/data/national_alters_nonhh_wave2_unweighted.csv\")\n",
    "df_w3_nonhhalters = pd.read_csv(\"/Users/chrissoria/documents/research/BICs/data/national_alters_nonhh_wave3_unweighted.csv\")\n",
    "df_w4_nonhhalters = pd.read_csv(\"/Users/chrissoria/documents/research/BICs/data/national_alters_nonhh_wave4_unweighted.csv\")\n",
    "df_w5_nonhhalters = pd.read_csv(\"/Users/chrissoria/documents/research/BICs/data/national_alters_nonhh_wave5_unweighted.csv\")\n",
    "df_w6_nonhhalters = pd.read_csv(\"/Users/chrissoria/documents/research/BICs/data/national_alters_nonhh_wave6_unweighted.csv\")\n",
    "\n",
    "df_alters_combined = pd.concat([df_w2_nonhhalters, df_w3_nonhhalters, df_w4_nonhhalters, df_w5_nonhhalters, df_w6_nonhhalters], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485215fe",
   "metadata": {},
   "source": [
    "what is num_cc_nonhh? \\\n",
    "Should I use this or how many reported contacts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "230348e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary indicators for mask, gloves, and other protective equipment usage\n",
    "df_alters_combined['Mask_Used'] = (\n",
    "    ((df_alters_combined['protection_1'] == \"Wear a face mask\") |\n",
    "    (df_alters_combined['protection_2'] == \"Wear a face mask\") |\n",
    "    (df_alters_combined['protection_3'] == \"Wear a face mask\") |\n",
    "    (df_alters_combined['protection_4'] == \"Wear a face mask\")).astype(int)\n",
    ")\n",
    "\n",
    "df_alters_combined['Gloves_Used'] = (\n",
    "    ((df_alters_combined['protection_1'] == \"Wear gloves\") |\n",
    "    (df_alters_combined['protection_2'] == \"Wear gloves\") |\n",
    "    (df_alters_combined['protection_3'] == \"Wear gloves\") |\n",
    "    (df_alters_combined['protection_4'] == \"Wear gloves\")).astype(int)\n",
    ")\n",
    "\n",
    "df_alters_combined['Other_Protective_Equipment_Used'] = (\n",
    "    ((df_alters_combined['protection_1'] == \"Wear other protective equipment\") |\n",
    "    (df_alters_combined['protection_2'] == \"Wear other protective equipment\") |\n",
    "    (df_alters_combined['protection_3'] == \"Wear other protective equipment\") |\n",
    "    (df_alters_combined['protection_4'] == \"Wear other protective equipment\")).astype(int)\n",
    ")\n",
    "\n",
    "# Aggregate these indicators at the 'rid' level\n",
    "df_aggregated = df_alters_combined.groupby('rid').agg(\n",
    "    Total_Masks_Used=('Mask_Used', 'sum'),\n",
    "    Total_Gloves_Used=('Gloves_Used', 'sum'),\n",
    "    Total_Other_Protective_Equipment_Used=('Other_Protective_Equipment_Used', 'sum'),\n",
    "    Contacts=('rid', 'size')\n",
    ").reset_index()\n",
    "\n",
    "# Normalize the counts by the number of contacts\n",
    "df_aggregated['Norm_Masks_Used'] = df_aggregated['Total_Masks_Used'] / df_aggregated['Contacts']\n",
    "df_aggregated['Norm_Gloves_Used'] = df_aggregated['Total_Gloves_Used'] / df_aggregated['Contacts']\n",
    "df_aggregated['Norm_Other_Protective_Equipment_Used'] = df_aggregated['Total_Other_Protective_Equipment_Used'] / df_aggregated['Contacts']\n",
    "\n",
    "# Calculate non-weighted and weighted safety indices\n",
    "df_aggregated['Non_Weighted_Safety_Index'] = (\n",
    "    df_aggregated['Norm_Masks_Used'] + \n",
    "    df_aggregated['Norm_Gloves_Used'] + \n",
    "    df_aggregated['Norm_Other_Protective_Equipment_Used']\n",
    ") / 3\n",
    "\n",
    "df_aggregated['Weighted_Safety_Index'] = (\n",
    "    df_aggregated['Norm_Masks_Used'] + \n",
    "    df_aggregated['Norm_Gloves_Used'] + \n",
    "    df_aggregated['Norm_Other_Protective_Equipment_Used']\n",
    ") / (3 * df_aggregated['Contacts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e77daca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_contacts = pd.merge(df_combined, df_aggregated, on = \"rid\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b7a6f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wave\n",
       "6    5418\n",
       "3    3248\n",
       "4    2993\n",
       "5    2976\n",
       "2    2432\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined_contacts['wave'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e64516b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "political_party\n",
       "Democrat                7361\n",
       "Republican              4814\n",
       "Independent             3968\n",
       "Prefer not to answer     924\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined_contacts['political_party'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82cb9bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_contacts.to_csv('data/BICS_ego_alters_merged.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60c1ab6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_types = {\n",
    "    'ZIP': str,\n",
    "    'CD':str,\n",
    "    'COUNTY_FIPS':str,\n",
    "    'STATE_FIPS':str,\n",
    "    'CONGRESSPERSON_PARTY': str\n",
    "}\n",
    "\n",
    "ZIP_FEATURES = pd.read_csv('/Users/chrissoria/Documents/Research/BICS_Political_Polarization/data/ZIP_Features.csv',\n",
    "                          dtype=col_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05fbda53",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['COUNTY_FIPS'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 22\u001b[0m\n\u001b[1;32m      8\u001b[0m all_waves \u001b[38;5;241m=\u001b[39m all_waves\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresp_zip\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZIP\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     10\u001b[0m })\n\u001b[1;32m     12\u001b[0m columns_to_keep \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResponseId\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStartDate\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresp_yob\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresp_sex\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresp_hispanic\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr_race\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresp_nativity\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZIP\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     13\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresp_hhsize\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr_working\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresp_occupation\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlefthome_num\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_cc_nonhh\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCOUNTY_FIPS\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     14\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlefthome_where_1\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlefthome_where_2\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlefthome_where_3\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlefthome_where_4\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlefthome_where_10\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_concern\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_concern_strong\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresp_educ\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresp_sex\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContacts\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNon_Weighted_Safety_Index\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     21\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeighted_Safety_Index\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_collected_dates\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 22\u001b[0m all_waves \u001b[38;5;241m=\u001b[39m all_waves[columns_to_keep]\n\u001b[1;32m     24\u001b[0m all_waves[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpolitical_party\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3766\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3767\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3769\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5874\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5877\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   5879\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   5880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5881\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:5941\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5940\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 5941\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['COUNTY_FIPS'] not in index\""
     ]
    }
   ],
   "source": [
    "col_types = {\n",
    "    'resp_zip': str,\n",
    "    'political_party': str\n",
    "}\n",
    "\n",
    "all_waves = df_combined_contacts\n",
    "\n",
    "all_waves = all_waves.rename(columns={\n",
    "    'resp_zip': 'ZIP'\n",
    "})\n",
    "\n",
    "columns_to_keep = ['ResponseId','StartDate','resp_yob','resp_sex','resp_hispanic','r_race','resp_nativity','ZIP',\n",
    "                  'resp_hhsize','r_working','resp_occupation','lefthome_num','num_cc_nonhh',\n",
    "                  'lefthome_where_1','lefthome_where_2','lefthome_where_3','lefthome_where_4','lefthome_where_10',\n",
    "                  'lefthome_where_8','lefthome_where_9','lefthome_where_5','lefthome_where_11','lefthome_where_6',\n",
    "                  'lefthome_where_7','inet_freq','socmedia_use','covid19_familiar','covid19_concern',\n",
    "                  'covid19_f2fchange','covid19_reduceOK','policy_sip','age','hhi','political_party','political_view',\n",
    "                  'industry','health_insurance','interview_date','wave','agecat','city','covid19_vax','covid19_whynot_vax',\n",
    "                  'Non_Weighted_Safety_Index','Weighted_Safety_Index','Norm_Masks_Used','educ_group','contact_reduction',\n",
    "                  'binary_concern','binary_concern_strong','resp_educ','resp_sex','Contacts','Non_Weighted_Safety_Index',\n",
    "                  'Weighted_Safety_Index','data_collected_dates']\n",
    "all_waves = all_waves[columns_to_keep]\n",
    "\n",
    "all_waves['political_party'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2692791d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BICS_ZIP_FEATURES = pd.merge(all_waves, ZIP_FEATURES, on = \"ZIP\", how = \"left\")\n",
    "BICS_ZIP_FEATURES = BICS_ZIP_FEATURES.drop_duplicates(subset='ResponseId', keep='first')\n",
    "BICS_ZIP_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e9f5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BICS_ZIP_FEATURES['political_party'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4081ad50",
   "metadata": {},
   "outputs": [],
   "source": [
    "BICS_ZIP_FEATURES['political_party_to_CD'] = BICS_ZIP_FEATURES.apply(\n",
    "    lambda row: str(row['political_party']) + \" in \" + str(row['CONGRESSPERSON_PARTY']) + \" led CD\", axis=1\n",
    ")\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(BICS_ZIP_FEATURES[['political_party', 'CONGRESSPERSON_PARTY', 'political_party_to_CD']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173187c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BICS_ZIP_FEATURES['political_party'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b97e85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BICS_ZIP_FEATURES['CONGRESSPERSON_PARTY'] = BICS_ZIP_FEATURES['CONGRESSPERSON_PARTY'].replace(\"Democratic\", \"Democrat\")\n",
    "BICS_ZIP_FEATURES['In_Opposing_Party_CD'] = (BICS_ZIP_FEATURES['political_party'] != BICS_ZIP_FEATURES['CONGRESSPERSON_PARTY']).astype(int)\n",
    "BICS_ZIP_FEATURES['Independent'] = (BICS_ZIP_FEATURES['political_party'] == \"Independent\").astype(int)\n",
    "BICS_ZIP_FEATURES['Vaccinated'] = BICS_ZIP_FEATURES['covid19_vax'].apply(\n",
    "    lambda x: 1 if x == \"Yes, I have received at least one dose of a vaccine\" else\n",
    "              (0 if x == \"No, I have not\" else np.nan)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cdc952",
   "metadata": {},
   "source": [
    "Does it make sense to drop Independents? \\\n",
    "They're kind of in their own cateogory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b77586",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(BICS_ZIP_FEATURES['In_Opposing_Party_CD'].value_counts())\n",
    "print(BICS_ZIP_FEATURES['political_party'].value_counts())\n",
    "print(BICS_ZIP_FEATURES['CONGRESSPERSON_PARTY'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d52f9c",
   "metadata": {},
   "source": [
    "Below I convert the raw numbers to categories for Trump and Biden share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba5e7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "BICS_ZIP_FEATURES['Categorical_Trump_County_Share'] = BICS_ZIP_FEATURES['trump_percentage_won'].apply(lambda x:\n",
    "    \"Less Than a Third\" if x < 33.1 else\n",
    "    \"Less than Two Thirds Greater Than One Third\" if x < 66.1 else\n",
    "    \"Greater than or Equal to Two thirds\" if x >= 66.1 else pd.NA\n",
    ")\n",
    "\n",
    "BICS_ZIP_FEATURES['Categorical_Biden_County_Share'] = BICS_ZIP_FEATURES['biden_percentage_won'].apply(lambda x:\n",
    "    \"Less Than a Third\" if x < 33.1 else\n",
    "    \"Less than Two Thirds Greater Than One Third\" if x < 66.1 else\n",
    "    \"Greater than or Equal to Two thirds\" if x >= 66.1 else pd.NA\n",
    ")\n",
    "\n",
    "BICS_ZIP_FEATURES['Percentage_Trump_Greater_Than_Two_Thirds'] = BICS_ZIP_FEATURES['trump_percentage_won'].apply(lambda x:\n",
    "    1 if x >= 66.1 else\n",
    "    0 if x < 66.1 else pd.NA\n",
    ")\n",
    "\n",
    "BICS_ZIP_FEATURES['Percentage_Trump_Less_Than_Two_Thirds'] = BICS_ZIP_FEATURES['trump_percentage_won'].apply(lambda x:\n",
    "    1 if x < 66.1 else\n",
    "    0 if x <= 66.1 else pd.NA\n",
    ")\n",
    "\n",
    "BICS_ZIP_FEATURES['Percentage_Biden_Greater_Than_Two_Thirds'] = BICS_ZIP_FEATURES['biden_percentage_won'].apply(lambda x:\n",
    "    1 if x >= 66.1 else\n",
    "    0 if x < 66.1 else pd.NA\n",
    ")\n",
    "\n",
    "BICS_ZIP_FEATURES['Percentage_Biden_Less_Than_Two_Thirds'] = BICS_ZIP_FEATURES['biden_percentage_won'].apply(lambda x:\n",
    "    1 if x < 66.1 else\n",
    "    0 if x <= 66.1 else pd.NA\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cfa0f1",
   "metadata": {},
   "source": [
    "Next, I use the same logic to create the CD categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3172e9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "BICS_ZIP_FEATURES['Categorical_Repub_CD_County_Share'] = BICS_ZIP_FEATURES['CD_PERCENT_REPUBLICAN'].apply(lambda x:\n",
    "    \"Less Than a Quarter\" if x < .25 else\n",
    "    \"Two Quarters\" if x < .50 and x >.25 else\n",
    "    \"Three Quarters\" if x < .75 and x > .50 else\n",
    "    \"Greater than or Equal to Three Quarters\" if x >= .75 else pd.NA\n",
    ")\n",
    "\n",
    "BICS_ZIP_FEATURES['Categorical_Dem_CD_County_Share'] = BICS_ZIP_FEATURES['CD_PERCENT_DEMOCRAT'].apply(lambda x:\n",
    "    \"Less Than a Quarter\" if x < .25 else\n",
    "    \"Two Quarters\" if x < .50 else\n",
    "    \"Three Quarters\" if x < .75 else\n",
    "    \"Greater than or Equal to Three Quarters\" if x >= .75 else pd.NA\n",
    ")\n",
    "\n",
    "BICS_ZIP_FEATURES['Categorical_Repub_CD_County_Share'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caae8348",
   "metadata": {},
   "source": [
    "Next, let's add a variable that treats urban and rural as a binary. \\\n",
    "1 = Metro - Counties in metro areas of 1 million population or more \\\n",
    "2 = Metro - Counties in metro areas of 250,000 to 1 million population \\         \n",
    "3 = Metro - Counties in metro areas of fewer than 250,000 population \\\n",
    "4 = Nonmetro - Urban population of 20,000 or more, adjacent to a metro area \\\n",
    "5 = Nonmetro - Urban population of 20,000 or more, not adjacent to a metro area \\\n",
    "6 = Nonmetro - Urban population of 2,500 to 19,999, adjacent to a metro area \\\n",
    "7 = Nonmetro - Urban population of 2,500 to 19,999, not adjacent to a metro area \\\n",
    "8 = Nonmetro - Completely rural or less than 2,500 urban population, adjacent to a metro area \\\n",
    "9 = Nonmetro - Completely rural or less than 2,500 urban population, not adjacent to a metro area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e0f267",
   "metadata": {},
   "outputs": [],
   "source": [
    "BICS_ZIP_FEATURES['COUNT_RUCC_CAT'] = BICS_ZIP_FEATURES['COUNTY_RUCC_2013'].apply(\n",
    "    lambda x: \"Urban Metro\" if x in [1, 2] else\n",
    "              \"Urban Nonmetro\" if x in list(range(3, 8)) else \n",
    "              \"Rural\" if x in [8, 9] else np.nan\n",
    ")\n",
    "\n",
    "BICS_ZIP_FEATURES['COUNT_RUCC_BINARY'] = BICS_ZIP_FEATURES['COUNTY_RUCC_2013'].apply(\n",
    "    lambda x: \"Urban\" if x in list(range(1, 8)) else  \n",
    "              \"Rural\" if x in [8, 9] else np.nan\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cb0f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "BICS_ZIP_FEATURES.to_csv('data/BICS_ZIP_Features.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1233a1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BICS_ZIP_FEATURES.to_csv('data/Partisanship and Health Behavior/Data/BICS_ZIP_Features.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
